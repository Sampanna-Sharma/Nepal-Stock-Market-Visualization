{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8b7b287e30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import ast\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing to include label and shift it one place up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "nepse_data = pd.read_csv(\"data_set_ready_for_training.csv\")\n",
    "nepse_data[\"news\"] = nepse_data[\"news\"].apply(ast.literal_eval)\n",
    "#nepse_data.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1318 entries, 0 to 1377\n",
      "Data columns (total 11 columns):\n",
      "closing_price    1318 non-null float64\n",
      "news             1318 non-null object\n",
      "momentum         1318 non-null float64\n",
      "EMA              1318 non-null float64\n",
      "MACD             1318 non-null float64\n",
      "RSI              1318 non-null float64\n",
      "ROI              1318 non-null float64\n",
      "ATR              1318 non-null float64\n",
      "williams         1318 non-null float64\n",
      "CCI              1318 non-null float64\n",
      "UO               1318 non-null float64\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 123.6+ KB\n"
     ]
    }
   ],
   "source": [
    "nepse_data = nepse_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "nepse_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(sorted(nepse_data.news.apply(len).to_list(), reverse=True)).hist(bins = 40)\n",
    "#most of the days has 20 news or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closing_price</th>\n",
       "      <th>news</th>\n",
       "      <th>momentum</th>\n",
       "      <th>EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ROI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>williams</th>\n",
       "      <th>CCI</th>\n",
       "      <th>UO</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975.0</td>\n",
       "      <td>[[0.2306930273771286, 0.792356550693512, 0.642...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>1087.863864</td>\n",
       "      <td>-58.947313</td>\n",
       "      <td>0.149378</td>\n",
       "      <td>1.126154</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>997.666667</td>\n",
       "      <td>0.154372</td>\n",
       "      <td>954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>954.0</td>\n",
       "      <td>[[0.31689509749412537, 0.8638337850570679, 0.6...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1067.269422</td>\n",
       "      <td>-65.253876</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.122642</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>966.666667</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917.0</td>\n",
       "      <td>[[0.31150949001312256, 0.7647785544395447, 0.6...</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>1044.151049</td>\n",
       "      <td>-72.401798</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.135878</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>0.069584</td>\n",
       "      <td>903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>903.0</td>\n",
       "      <td>[[0.1868913620710373, 0.7952941060066223, 0.61...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>1022.435502</td>\n",
       "      <td>-78.293327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.120598</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>885.0</td>\n",
       "      <td>[[0.3303453326225281, 0.8576347231864929, 0.68...</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1001.291578</td>\n",
       "      <td>-83.452392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.108927</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>0.108076</td>\n",
       "      <td>897.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closing_price                                               news  momentum  \\\n",
       "0          975.0  [[0.2306930273771286, 0.792356550693512, 0.642...     -87.0   \n",
       "1          954.0  [[0.31689509749412537, 0.8638337850570679, 0.6...      -2.0   \n",
       "2          917.0  [[0.31150949001312256, 0.7647785544395447, 0.6...     -75.0   \n",
       "3          903.0  [[0.1868913620710373, 0.7952941060066223, 0.61...     -87.0   \n",
       "4          885.0  [[0.3303453326225281, 0.8576347231864929, 0.68...     -90.0   \n",
       "\n",
       "           EMA       MACD       RSI       ROI    ATR  williams         CCI  \\\n",
       "0  1087.863864 -58.947313  0.149378  1.126154  106.0  0.820755  997.666667   \n",
       "1  1067.269422 -65.253876  0.250000  1.122642   38.0  1.000000  966.666667   \n",
       "2  1044.151049 -72.401798  0.480000  1.135878   75.0  1.000000  942.000000   \n",
       "3  1022.435502 -78.293327  0.000000  1.120598   87.0  1.000000  932.000000   \n",
       "4  1001.291578 -83.452392  0.000000  1.108927   90.0  1.000000  915.000000   \n",
       "\n",
       "         UO  Label  \n",
       "0  0.154372  954.0  \n",
       "1  0.105707  917.0  \n",
       "2  0.069584  903.0  \n",
       "3  0.068895  885.0  \n",
       "4  0.108076  897.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nepse_data['Label'] = nepse_data['closing_price'].rolling(window=2).apply(lambda x:  1 if x[1]>x[0] else 0 )\n",
    "nepse_data['Label'] = nepse_data['closing_price'].shift(-1)\n",
    "#nepse_data.Label = nepse_data.Label.shift(-1)\n",
    "nepse_data = nepse_data[:-1]\n",
    "nepse_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here on, data is prepared to be fed to pytorch network\n",
    "\n",
    "The dataset is prepared by inheriting Dataset class, and DataLoader class is used for batching. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader class\n",
    "class NepseDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.features = dataset.loc[:, [\"closing_price\", \"momentum\",\"EMA\",\"MACD\",\"RSI\",\"ROI\",\"ATR\",\"williams\",\n",
    "                                \"CCI\",\"UO\"]].values\n",
    "        self.label =  dataset['Label'].values\n",
    "        self.news = dataset['news'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tech_indicators = self.features[idx,:]\n",
    "        label = self.label[idx]\n",
    "        news = self.news[idx]\n",
    "        sample = {'news': torch.tensor(news),'tech_indicators': torch.tensor(tech_indicators)\n",
    "                  ,'label': torch.tensor(label)}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_zeros(news):\n",
    "    padding_dims = 20 - len(news)\n",
    "    for _ in range(padding_dims):\n",
    "        news.append([0]*100)\n",
    "    return news\n",
    "def truncate(news):\n",
    "    return news[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_dimens(news):  \n",
    "    if len(news)<20:\n",
    "        news = append_zeros(news)\n",
    "    elif len(news)>20:\n",
    "        news = truncate(news)\n",
    "    \n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepse_data[\"news\"] = nepse_data[\"news\"].apply(const_dimens)\n",
    "\n",
    "test_data = NepseDataset(nepse_data)\n",
    "print(len(test_data))\n",
    "test_data[0]['news'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news': tensor([[[ 0.2307,  0.7924,  0.6421,  ..., -0.2635,  0.2692, -0.0625],\n",
      "         [ 0.4144,  0.8800,  0.7002,  ..., -0.3542,  0.0610, -0.1523],\n",
      "         [ 0.4557,  0.9929,  0.7184,  ..., -0.3667,  0.0949, -0.2086],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]), 'tech_indicators': tensor([[ 9.7500e+02, -8.7000e+01,  1.0879e+03, -5.8947e+01,  1.4938e-01,\n",
      "          1.1262e+00,  1.0600e+02,  8.2075e-01,  9.9767e+02,  1.5437e-01]],\n",
      "       dtype=torch.float64), 'label': tensor([954.])}\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(test_data, batch_size=1)\n",
    "for i, sample in enumerate(data):\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,4)\n",
    "b = torch.randn(3,6)\n",
    "torch.cat((a,b),dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Neural Network\n",
    " The network consists of CNN which extracts features from news, the output of which is concatenated with the technical indicators and fed to lstm. The output is then fed to softmax to predict the rise or fall in nepse for the following day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class StockNN(nn.Module):\n",
    "    def __init__(self, filter_sizes, drop_prob, embedding_dim, length_of_features, n_hidden_lstm=256, n_layers=1):\n",
    "        super(StockNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden_lstm = n_hidden_lstm\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = 1, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        self.lstm = nn.LSTM(length_of_features, n_hidden_lstm, n_layers, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(n_hidden_lstm)\n",
    "        self.linear = nn.Linear(n_hidden_lstm, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,hc):\n",
    "        \n",
    "        #x_cnn = x['news']\n",
    "        #x_cnn = x_cnn.reshape(x_cnn.shape[0],1,x_cnn.shape[1], x_cnn.shape[2])\n",
    "        #print(x_cnn.shape)\n",
    "        #conved = [F.relu(conv(x_cnn)).squeeze(3) for conv in self.convs]\n",
    "        #print(x.shape for x in list(conved))\n",
    "        #pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        #print(x.shape for x in list(pooled))\n",
    "        #stock_features = torch.cat(pooled, dim = 1)\n",
    "        #print(stock_features.shape)\n",
    "        #print(x['tech_indicators'].shape)\n",
    "        \n",
    "        #stock_features = torch.cat([stock_features,x['tech_indicators'].float()], dim=1)\n",
    "        stock_features = x['tech_indicators'].float()\n",
    "        #print(stock_features.shape)\n",
    "        out, (h,c) = self.lstm(stock_features.view(stock_features.shape[0],1,-1),hc)\n",
    "        #out = self.batch_norm(out.view(out.shape[0],-1))\n",
    "        hidden_2_risefall = self.linear(out.view(out.shape[0],-1))\n",
    "        rise_fall = F.relu(hidden_2_risefall)\n",
    "        \n",
    "        return rise_fall, (h,c)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.n_hidden_lstm),\n",
    "                torch.zeros(self.n_layers, batch_size, self.n_hidden_lstm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317 0\n"
     ]
    }
   ],
   "source": [
    "rad_fn=<ReluBackward0>)\n",
    "def train_validate_set(data,val_frac=0):\n",
    "    m = data.shape[0]\n",
    "    val_idx = int(m*(1-val_frac))\n",
    "    test_data, val_data = NepseDataset(data.head(val_idx)), NepseDataset(data.tail(m - val_idx))\n",
    "    return test_data, val_data\n",
    "\n",
    "td, vd = train_validate_set(nepse_data) \n",
    "print(len(td), len(vd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the StockNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have to check this one\n",
    "def train(NN, data, val_frac=0.2, max_epochs=10, batch_size=10, learning_rate=1e-3):\n",
    "    last_loss = 100\n",
    "    NN.train()\n",
    "    opt = torch.optim.Adam(NN.parameters(),lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    train_data, validate_data = train_validate_set(data,val_frac)\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    for e in range(max_epochs):\n",
    "        hc = NN.init_hidden(batch_size)\n",
    "        \n",
    "        for i_batch, batched_sample in enumerate(dataloader):\n",
    "            if len(batched_sample['label']) < batch_size:\n",
    "                continue\n",
    "            xtrain = dict(news = batched_sample[\"news\"],tech_indicators = batched_sample['tech_indicators'])\n",
    "            out, hc= NN(xtrain,hc)\n",
    "        \n",
    "            loss = criterion(out,batched_sample['label'].float())\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            opt.step()\n",
    "            \n",
    "            if(i_batch % 10 ==0):\n",
    "                print(e, i_batch,loss.item(),(\"badyo\" if last_loss < loss.item() else \"ghatyo\"))\n",
    "                last_loss = loss.item()\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = dict(x = [2,3,4], y= [2,3,4], z= [6,7,9])\n",
    "c['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_net = StockNN([2,2,3,3,4,4], 0, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 909391.4375 badyo\n",
      "0 10 879573.5625 ghatyo\n",
      "0 20 892695.4375 badyo\n",
      "0 30 857297.3125 ghatyo\n",
      "0 40 748242.5 ghatyo\n",
      "0 50 712519.6875 ghatyo\n",
      "0 60 629069.125 ghatyo\n",
      "0 70 676123.0625 badyo\n",
      "0 80 691174.75 badyo\n",
      "0 90 689677.3125 ghatyo\n",
      "0 100 733753.0625 badyo\n",
      "0 110 706795.375 ghatyo\n",
      "0 120 753075.25 badyo\n",
      "0 130 1140407.375 badyo\n",
      "0 140 2087354.375 badyo\n",
      "0 150 1714799.25 ghatyo\n",
      "0 160 1459874.0 ghatyo\n",
      "0 170 1409183.5 ghatyo\n",
      "0 180 1592564.875 badyo\n",
      "0 190 2116557.5 badyo\n",
      "0 200 2043928.5 ghatyo\n",
      "0 210 2037666.625 ghatyo\n",
      "0 220 1966426.25 ghatyo\n",
      "0 230 1991163.875 badyo\n",
      "0 240 1263235.25 ghatyo\n",
      "0 250 2178327.75 badyo\n",
      "0 260 2050145.75 ghatyo\n",
      "0 270 2303460.25 badyo\n",
      "0 280 2671774.5 badyo\n",
      "0 290 2459740.75 ghatyo\n",
      "0 300 2481180.25 badyo\n",
      "0 310 3301429.5 badyo\n",
      "0 320 3507081.5 badyo\n",
      "0 330 3092102.5 ghatyo\n",
      "0 340 3176195.25 badyo\n",
      "0 350 2772151.5 ghatyo\n",
      "0 360 2923492.25 badyo\n",
      "0 370 2899128.0 ghatyo\n",
      "0 380 2817546.75 ghatyo\n",
      "0 390 2881316.5 badyo\n",
      "0 400 3313608.75 badyo\n",
      "0 410 3475193.75 badyo\n",
      "0 420 3232894.75 ghatyo\n",
      "0 430 3139574.75 ghatyo\n",
      "0 440 3727777.75 badyo\n",
      "0 450 3707851.0 ghatyo\n",
      "0 460 4361400.0 badyo\n",
      "0 470 4614611.0 badyo\n",
      "0 480 6354883.5 badyo\n",
      "0 490 4794226.5 ghatyo\n",
      "0 500 4487165.0 ghatyo\n",
      "0 510 4088752.0 ghatyo\n",
      "0 520 4165243.5 badyo\n",
      "0 530 4283860.0 badyo\n",
      "0 540 3406322.25 ghatyo\n",
      "0 550 3358284.0 ghatyo\n",
      "0 560 3711507.5 badyo\n",
      "0 570 3498741.5 ghatyo\n",
      "0 580 3457572.75 ghatyo\n",
      "0 590 4009705.0 badyo\n",
      "0 600 5043106.0 badyo\n",
      "0 610 6172062.0 badyo\n",
      "0 620 6394854.5 badyo\n",
      "0 630 5651296.5 ghatyo\n",
      "0 640 5465015.5 ghatyo\n",
      "0 650 4947517.0 ghatyo\n",
      "0 660 5372849.0 badyo\n",
      "0 670 5160176.0 ghatyo\n",
      "0 680 4567999.5 ghatyo\n",
      "0 690 2759176.0 ghatyo\n",
      "0 700 2666569.75 ghatyo\n",
      "0 710 3203879.75 badyo\n",
      "0 720 3261315.0 badyo\n",
      "0 730 3712816.25 badyo\n",
      "0 740 3681735.0 ghatyo\n",
      "0 750 3377138.5 ghatyo\n",
      "0 760 3285632.5 ghatyo\n",
      "0 770 3188308.0 ghatyo\n",
      "0 780 3457936.0 badyo\n",
      "0 790 2661893.75 ghatyo\n",
      "0 800 3358197.75 badyo\n",
      "0 810 3299753.75 ghatyo\n",
      "0 820 4864224.0 badyo\n",
      "0 830 5733063.0 badyo\n",
      "0 840 6160983.5 badyo\n",
      "0 850 5821644.0 ghatyo\n",
      "0 860 5719167.0 ghatyo\n",
      "0 870 5171795.5 ghatyo\n",
      "0 880 4743270.5 ghatyo\n",
      "0 890 4438215.5 ghatyo\n",
      "0 900 3206117.25 ghatyo\n",
      "0 910 2871380.75 ghatyo\n",
      "0 920 2868098.0 ghatyo\n",
      "0 930 3285552.25 badyo\n",
      "0 940 3210052.25 ghatyo\n",
      "0 950 3231744.5 badyo\n",
      "0 960 3235476.5 badyo\n",
      "0 970 3915576.25 badyo\n",
      "0 980 4027157.75 badyo\n",
      "0 990 4790470.5 badyo\n",
      "0 1000 4463088.5 ghatyo\n",
      "0 1010 4517639.0 badyo\n",
      "0 1020 4810788.0 badyo\n",
      "0 1030 5254269.0 badyo\n",
      "0 1040 5067260.5 ghatyo\n",
      "0 1050 4936740.5 ghatyo\n",
      "1 0 732275.6875 ghatyo\n",
      "1 10 671365.1875 ghatyo\n",
      "1 20 683587.625 badyo\n",
      "1 30 653367.625 ghatyo\n",
      "1 40 558860.375 ghatyo\n",
      "1 50 527837.75 ghatyo\n",
      "1 60 457026.75 ghatyo\n",
      "1 70 497447.46875 badyo\n",
      "1 80 511031.0 badyo\n",
      "1 90 510413.875 ghatyo\n",
      "1 100 549083.5625 badyo\n",
      "1 110 526441.5625 ghatyo\n",
      "1 120 567128.4375 badyo\n",
      "1 130 909189.8125 badyo\n",
      "1 140 1771161.375 badyo\n",
      "1 150 1430568.375 ghatyo\n",
      "1 160 1199604.625 ghatyo\n",
      "1 170 1154585.375 ghatyo\n",
      "1 180 1322004.75 badyo\n",
      "1 190 1803737.25 badyo\n",
      "1 200 1737715.125 ghatyo\n",
      "1 210 1732871.75 ghatyo\n",
      "1 220 1668081.375 ghatyo\n",
      "1 230 1691800.0 badyo\n",
      "1 240 1027918.375 ghatyo\n",
      "1 250 1866308.875 badyo\n",
      "1 260 1748571.375 ghatyo\n",
      "1 270 1983873.25 badyo\n",
      "1 280 2327503.25 badyo\n",
      "1 290 2130662.0 ghatyo\n",
      "1 300 2151338.0 badyo\n",
      "1 310 2919937.5 badyo\n",
      "1 320 3114301.25 badyo\n",
      "1 330 2724663.25 ghatyo\n",
      "1 340 2804236.0 badyo\n",
      "1 350 2425919.25 ghatyo\n",
      "1 360 2568092.25 badyo\n",
      "1 370 2545691.25 ghatyo\n",
      "1 380 2469672.75 ghatyo\n",
      "1 390 2529765.25 badyo\n",
      "1 400 2936144.5 badyo\n",
      "1 410 3088703.25 badyo\n",
      "1 420 2860820.75 ghatyo\n",
      "1 430 2773335.75 ghatyo\n",
      "1 440 3327938.0 badyo\n",
      "1 450 3309327.25 ghatyo\n",
      "1 460 3928415.0 badyo\n",
      "1 470 4169055.0 badyo\n",
      "1 480 5830155.5 badyo\n",
      "1 490 4339960.0 ghatyo\n",
      "1 500 4048023.25 ghatyo\n",
      "1 510 3670018.0 ghatyo\n",
      "1 520 3742434.75 badyo\n",
      "1 530 3854824.5 badyo\n",
      "1 540 3024876.25 ghatyo\n",
      "1 550 2979529.75 ghatyo\n",
      "1 560 3312656.0 badyo\n",
      "1 570 3111715.0 ghatyo\n",
      "1 580 3072779.5 ghatyo\n",
      "1 590 3594318.5 badyo\n",
      "1 600 4626072.0 badyo\n",
      "1 610 5652826.5 badyo\n",
      "1 620 5867245.5 badyo\n",
      "1 630 5156734.5 ghatyo\n",
      "1 640 4978951.5 ghatyo\n",
      "1 650 4485834.0 ghatyo\n",
      "1 660 4891413.5 badyo\n",
      "1 670 4688697.5 ghatyo\n",
      "1 680 4125134.5 ghatyo\n",
      "1 690 2417548.5 ghatyo\n",
      "1 700 2331199.75 ghatyo\n",
      "1 710 2835317.0 badyo\n",
      "1 720 2889451.25 badyo\n",
      "1 730 3315377.75 badyo\n",
      "1 740 3286079.5 ghatyo\n",
      "1 750 2998248.75 ghatyo\n",
      "1 760 2911957.75 ghatyo\n",
      "1 770 2820254.5 ghatyo\n",
      "1 780 3074050.0 badyo\n",
      "1 790 2326370.0 ghatyo\n",
      "1 800 2979854.0 badyo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0724382a5c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnepse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-cabcce0d9f51>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(NN, data, val_frac, max_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train(stock_net, nepse_data, max_epochs= 500, batch_size=1, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2037]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1899]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2095]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2060]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2068]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2340]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2159]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2126]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1671]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1680]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1881]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1633]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1311]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1288]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1336]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1466]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1478]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1485]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1319]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1216]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1197]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1284]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1464]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1466]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1464]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1480]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1293]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1497]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1467]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1518]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1489]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1492]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1515]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1337]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1261]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1258]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1198]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1462]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1493]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1225]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1257]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1279]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1506]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1499]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1473]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1264]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1278]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1490]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1483]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1368]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1188]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1220]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1299]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1286]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1449]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1445]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1445]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1509]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1477]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1376]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1278]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1497]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1509]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1424]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1489]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1214]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1228]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1424]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1405]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1404]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1020]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1208]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1218]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1059]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0953]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1081]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0999]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0977]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1132]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1205]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0917]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1203]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1263]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1986]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1248]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1275]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0798]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0943]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0871]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1064]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1436]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1642]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1162]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1201]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1077]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0965]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1072]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0890]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1055]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1301]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1282]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1235]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1285]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1288]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1303]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1306]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1284]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1265]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1262]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1268]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0995]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1026]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0975]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1248]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1267]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1000]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0914]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0947]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0982]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1203]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1183]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1103]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0880]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0916]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0882]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0877]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0881]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0877]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1075]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0938]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0763]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1134]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1240]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1161]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1147]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1061]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0866]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1066]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1171]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1168]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1191]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1176]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1111]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1173]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1135]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1145]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1156]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1223]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1218]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1210]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1189]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1194]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1213]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1223]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1206]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1231]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0942]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0976]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0989]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0953]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1139]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1150]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1163]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1202]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1230]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1235]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1231]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1236]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1229]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1231]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1259]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1392]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1939]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2007]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1842]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1811]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1802]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2057]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2094]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2123]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2077]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1741]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1451]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1513]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1124]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1028]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1196]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1239]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1741]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1649]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1598]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1230]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1260]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1635]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1628]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1603]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1300]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1304]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1217]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1184]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1193]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1189]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1452]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1371]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1332]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1416]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1443]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1475]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1449]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1432]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1666]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1674]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1676]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1669]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1437]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1569]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1568]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1585]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1574]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1579]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1621]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1302]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1258]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1300]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1294]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1480]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1506]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1452]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1299]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1077]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1079]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1159]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1075]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1359]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1413]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1083]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1333]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1194]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1153]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1616]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1614]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1606]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1651]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1641]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1620]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1643]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1644]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1656]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1648]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1583]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1579]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1593]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1644]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1610]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1582]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1659]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1662]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1649]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1630]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1581]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1672]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1665]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1663]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1670]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1392]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1646]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1451]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1575]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1591]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1572]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1237]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1578]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1595]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1576]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1575]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1570]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1582]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1583]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1594]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1593]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1321]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1611]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1609]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1568]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1567]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1568]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1520]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1283]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1335]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1411]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1199]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1239]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1291]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1233]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1339]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1491]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1490]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1417]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1331]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1444]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1520]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1571]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1593]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1591]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1607]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1627]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1597]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1580]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1585]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1581]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1410]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1292]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1337]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1302]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1295]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1125]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1456]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1517]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1469]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1478]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1478]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1479]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1501]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1224]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1251]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1265]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1312]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1297]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1335]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1293]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1086]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1106]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1089]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1324]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1352]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1459]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1420]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1420]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1403]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1174]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1465]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1570]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1715]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1091]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1153]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1374]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1638]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1800]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1129]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1346]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1656]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1118]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1259]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1151]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1388]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1673]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1608]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1578]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1621]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1637]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1700]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1670]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1324]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1249]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1638]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1502]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1595]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1574]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1628]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1365]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1520]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1491]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1596]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1553]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1603]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1633]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1606]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1632]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1682]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1304]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1682]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1526]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1596]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1309]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1562]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1356]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1465]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1426]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1529]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1542]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1596]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1461]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1225]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1229]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1299]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1252]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1574]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1414]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1251]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1208]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1417]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1364]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1069]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1083]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1180]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0716]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0764]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0800]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0521]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0354]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0689]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0767]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0679]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0672]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0662]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0669]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0677]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0723]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0755]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0795]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0757]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0830]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0665]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1113]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0672]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0697]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0858]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0953]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0674]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1040]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1129]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1310]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1254]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1089]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1281]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1321]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1310]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1274]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1371]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1365]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1368]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1374]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1360]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1399]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1360]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1326]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1314]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1443]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1365]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1383]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1151]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1405]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1432]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1304]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1469]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1581]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1363]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1570]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1431]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1457]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1334]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1387]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1369]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1267]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1092]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1159]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1372]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1379]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1287]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1390]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1467]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1451]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1400]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1402]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1407]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1402]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1386]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1288]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1290]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1355]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1444]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1440]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1307]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2111]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1784]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2379]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2267]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1876]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1884]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1887]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1906]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1932]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1909]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1911]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2111]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1971]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1806]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1731]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1615]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1521]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1443]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1395]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1392]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1492]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1591]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1479]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1722]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1691]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1553]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1295]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1376]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1407]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1312]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1521]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1441]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1177]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1176]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1287]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1205]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1448]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1485]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1528]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1515]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1497]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1537]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1562]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1571]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1600]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1585]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1572]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1540]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1513]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1578]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1515]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1564]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1563]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1566]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1577]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1576]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1316]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1579]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1382]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1566]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1602]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1428]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1290]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1505]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1689]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1789]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1290]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1284]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1204]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1176]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1291]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1540]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1526]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1518]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1541]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1283]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1437]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1116]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1248]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1053]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1034]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1029]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1387]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1057]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1421]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1054]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1014]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1041]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1642]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1830]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1947]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1962]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1813]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1401]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1351]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1716]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1582]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1631]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1419]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1655]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1210]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1325]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1342]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1371]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1721]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1718]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1630]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1594]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1367]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1480]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1696]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1575]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1656]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1755]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1404]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1655]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1493]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1492]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1676]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1460]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1728]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1761]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1614]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1531]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1353]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1601]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1637]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1689]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1698]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1401]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1421]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1442]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1446]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1632]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1532]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1412]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1424]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1224]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1208]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0741]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1661]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1881]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1909]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1912]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1907]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1928]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1999]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1923]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1925]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1913]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1796]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1671]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1696]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1438]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1327]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1321]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1436]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1583]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1620]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1642]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1341]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1382]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1375]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1532]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1553]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1562]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1282]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1305]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1577]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1540]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1335]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1430]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1354]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1226]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1334]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1337]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1359]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1291]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1320]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1386]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1325]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1156]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1046]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1385]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1382]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1059]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1108]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1358]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1532]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1450]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1450]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1493]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1531]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1537]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1491]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1465]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1509]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1439]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1402]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1505]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1542]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1620]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1654]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1577]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1415]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1381]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1317]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1406]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1192]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1317]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1466]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1571]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1293]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1408]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1426]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1453]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1506]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1453]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1708]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1749]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1694]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1464]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1655]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1595]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1594]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1640]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1346]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1485]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1209]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1259]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1495]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1541]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1541]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1848]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1650]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2084]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2034]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1853]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1870]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1934]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1924]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1936]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1917]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1876]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1868]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1889]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1878]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1843]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1849]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1860]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1848]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1895]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1458]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1567]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1716]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1750]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1529]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1473]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1401]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1513]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1761]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1827]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1944]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1795]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1429]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1627]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1399]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1407]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1387]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1376]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1372]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1440]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1528]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1529]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1436]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1408]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1400]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1405]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1686]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1444]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1543]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1437]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1370]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1389]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1632]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1430]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1423]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1453]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1415]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1472]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1697]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1386]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1722]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1454]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1395]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1398]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1432]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1679]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1648]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1475]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1318]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1325]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1327]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1314]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1414]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1393]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1449]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1384]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1360]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1471]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "stock_net.eval()\n",
    "hc = stock_net.init_hidden(1)\n",
    "train_data, validate_data = train_validate_set(nepse_data,0.1)\n",
    "dataloader = DataLoader(train_data, batch_size=1)\n",
    "milyo = 0\n",
    "for train in dataloader:\n",
    "    out, hc= stock_net(train,hc)\n",
    "    print(out)\n",
    "    if (train[\"label\"].data.cpu().numpy() ==np.argmax(out.data.cpu().numpy())):\n",
    "        milyo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n"
     ]
    }
   ],
   "source": [
    "print(milyo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
