{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepse_data = pd.read_csv(\"data_set_ready_for_training.csv\")\n",
    "nepse_data[\"news\"] = nepse_data[\"news\"].apply(ast.literal_eval)\n",
    "nepse_data = nepse_data.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closing_price</th>\n",
       "      <th>news</th>\n",
       "      <th>momentum</th>\n",
       "      <th>EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ROI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>williams</th>\n",
       "      <th>CCI</th>\n",
       "      <th>UO</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1273.0</td>\n",
       "      <td>[[0.36220553517341614, 0.9683135151863098, 0.5...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1257.027190</td>\n",
       "      <td>-82.501011</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.967400</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>1252.666667</td>\n",
       "      <td>0.517338</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>1277.0</td>\n",
       "      <td>[[0.38373106718063354, 0.8309400081634521, 0.5...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1260.099930</td>\n",
       "      <td>-74.796552</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>0.965309</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>1254.000000</td>\n",
       "      <td>0.495022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1272.0</td>\n",
       "      <td>[[0.3729100525379181, 0.8552981615066528, 0.60...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1261.930710</td>\n",
       "      <td>-68.306774</td>\n",
       "      <td>5.235294</td>\n",
       "      <td>0.971226</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>1258.666667</td>\n",
       "      <td>0.489393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>1265.0</td>\n",
       "      <td>[[0.15445244312286377, 0.6669142842292786, 0.7...</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1262.402908</td>\n",
       "      <td>-63.002169</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0.980316</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1271.666667</td>\n",
       "      <td>0.453701</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>[[0.3814601004123688, 0.7400802969932556, 0.64...</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1261.571692</td>\n",
       "      <td>-58.766343</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.990692</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1263.666667</td>\n",
       "      <td>0.465451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      closing_price                                               news  \\\n",
       "1372         1273.0  [[0.36220553517341614, 0.9683135151863098, 0.5...   \n",
       "1373         1277.0  [[0.38373106718063354, 0.8309400081634521, 0.5...   \n",
       "1374         1272.0  [[0.3729100525379181, 0.8552981615066528, 0.60...   \n",
       "1375         1265.0  [[0.15445244312286377, 0.6669142842292786, 0.7...   \n",
       "1376         1257.0  [[0.3814601004123688, 0.7400802969932556, 0.64...   \n",
       "\n",
       "      momentum          EMA       MACD       RSI       ROI   ATR  williams  \\\n",
       "1372      73.0  1257.027190 -82.501011  5.000000  0.967400  85.0  0.141176   \n",
       "1373      77.0  1260.099930 -74.796552  7.416667  0.965309  85.0  0.094118   \n",
       "1374      53.0  1261.930710 -68.306774  5.235294  0.971226  66.0  0.196970   \n",
       "1375     -20.0  1262.402908 -63.002169  2.916667  0.980316  20.0  1.000000   \n",
       "1376     -16.0  1261.571692 -58.766343  0.125000  0.990692  20.0  1.000000   \n",
       "\n",
       "              CCI        UO  Label  \n",
       "1372  1252.666667  0.517338    1.0  \n",
       "1373  1254.000000  0.495022    0.0  \n",
       "1374  1258.666667  0.489393    0.0  \n",
       "1375  1271.666667  0.453701    0.0  \n",
       "1376  1263.666667  0.465451    0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepse_data[\"Label\"] = nepse_data[\"closing_price\"].rolling(window=2).apply(lambda x:  1 if x[1]>x[0] else 0 )\n",
    "nepse_data.Label = nepse_data.Label.shift(-1)\n",
    "nepse_data = nepse_data[:-1]\n",
    "nepse_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nepse_data.loc[:, [\"closing_price\", \"momentum\",\"EMA\",\"MACD\",\"RSI\",\"ROI\",\"ATR\",\"williams\",\n",
    "                                \"CCI\",\"UO\",\"Label\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 40\n",
    "forward_days = 1\n",
    "num_periods = 20\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(look_back,len(dataset)-1):\n",
    "        a = dataset[(i) : i - look_back : -1,:10]\n",
    "        dataX.append(list(reversed(a)))\n",
    "        dataY.append(dataset[i+1,10])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(data, look_back=look_back )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.75000000e+03,  2.20000000e+01,  1.69889004e+03,\n",
       "          5.77275023e+01,  3.76666667e+00,  9.69485714e-01,\n",
       "          5.20000000e+01,  5.76923077e-01,  1.75266667e+03,\n",
       "          8.24229401e-01],\n",
       "        [ 1.72000000e+03, -4.80000000e+01,  1.70213773e+03,\n",
       "          5.51353761e+01,  8.66666667e-01,  9.92209302e-01,\n",
       "          6.00000000e+01,  1.00000000e+00,  1.74000000e+03,\n",
       "          7.18564310e-01],\n",
       "        [ 1.71800000e+03, -6.20000000e+01,  1.70457808e+03,\n",
       "          5.23166405e+01,  1.93548387e-01,  9.98952270e-01,\n",
       "          6.20000000e+01,  1.00000000e+00,  1.73866667e+03,\n",
       "          6.24764099e-01],\n",
       "        [ 1.73700000e+03, -2.10000000e+01,  1.70956607e+03,\n",
       "          5.10276979e+01,  3.06451613e-01,  9.93897524e-01,\n",
       "          4.00000000e+01,  5.25000000e-01,  1.73766667e+03,\n",
       "          6.68803539e-01],\n",
       "        [ 1.73500000e+03, -1.50000000e+01,  1.71347898e+03,\n",
       "          4.92767862e+01,  4.52380952e-01,  1.00063401e+00,\n",
       "          3.20000000e+01,  4.68750000e-01,  1.73433333e+03,\n",
       "          7.20394220e-01],\n",
       "        [ 1.72000000e+03,  0.00000000e+00,  1.71448221e+03,\n",
       "          4.61468492e+01,  3.87755102e-01,  1.01244186e+00,\n",
       "          1.90000000e+01,  8.94736842e-01,  1.72500000e+03,\n",
       "          6.42510619e-01],\n",
       "        [ 1.72900000e+03,  1.10000000e+01,  1.71671572e+03,\n",
       "          4.38866781e+01,  1.47368421e+00,  1.00722961e+00,\n",
       "          1.90000000e+01,  4.21052632e-01,  1.72800000e+03,\n",
       "          6.49029129e-01],\n",
       "        [ 1.73000000e+03, -7.00000000e+00,  1.71875945e+03,\n",
       "          4.16955278e+01,  1.70588235e+00,  1.00445087e+00,\n",
       "          1.70000000e+01,  4.11764706e-01,  1.72900000e+03,\n",
       "          5.85987378e-01],\n",
       "        [ 1.72900000e+03, -6.00000000e+00,  1.72033492e+03,\n",
       "          3.94238798e+01,  5.55555556e-01,  1.00208213e+00,\n",
       "          1.50000000e+01,  4.00000000e-01,  1.72800000e+03,\n",
       "          4.46959091e-01],\n",
       "        [ 1.76700000e+03,  4.70000000e+01,  1.72751417e+03,\n",
       "          4.02261627e+01,  3.00000000e+00,  9.81041313e-01,\n",
       "          4.70000000e+01,  0.00000000e+00,  1.75133333e+03,\n",
       "          6.94363771e-01],\n",
       "        [ 1.76200000e+03,  3.30000000e+01,  1.73281968e+03,\n",
       "          3.99974536e+01,  8.00000000e+00,  9.84506243e-01,\n",
       "          3.80000000e+01,  1.31578947e-01,  1.75266667e+03,\n",
       "          7.77374894e-01],\n",
       "        [ 1.73700000e+03,  7.00000000e+00,  1.73346281e+03,\n",
       "          3.73681522e+01,  1.25806452e+00,  9.99654577e-01,\n",
       "          3.80000000e+01,  7.89473684e-01,  1.74433333e+03,\n",
       "          6.13745329e-01],\n",
       "        [ 1.70000000e+03, -2.90000000e+01,  1.72831468e+03,\n",
       "          3.19307434e+01,  5.58823529e-01,  1.02035294e+00,\n",
       "          6.70000000e+01,  1.00000000e+00,  1.72233333e+03,\n",
       "          3.80422446e-01],\n",
       "        [ 1.66500000e+03, -1.02000000e+02,  1.71857396e+03,\n",
       "          2.45147593e+01,  3.72549020e-01,  1.03747748e+00,\n",
       "          1.02000000e+02,  1.00000000e+00,  1.69900000e+03,\n",
       "          2.41313074e-01],\n",
       "        [ 1.69400000e+03, -6.80000000e+01,  1.71479335e+03,\n",
       "          2.07385353e+01,  2.84313725e-01,  1.01729634e+00,\n",
       "          9.70000000e+01,  7.01030928e-01,  1.70700000e+03,\n",
       "          2.86600886e-01],\n",
       "        [ 1.67500000e+03, -6.20000000e+01,  1.70867130e+03,\n",
       "          1.60279490e+01,  2.50000000e-01,  1.02614925e+00,\n",
       "          7.20000000e+01,  8.61111111e-01,  1.69233333e+03,\n",
       "          3.85066764e-01],\n",
       "        [ 1.63400000e+03, -6.60000000e+01,  1.69718341e+03,\n",
       "          8.88400886e+00,  2.19696970e-01,  1.04608323e+00,\n",
       "          6.60000000e+01,  1.00000000e+00,  1.65600000e+03,\n",
       "          2.66098643e-01],\n",
       "        [ 1.63000000e+03, -3.50000000e+01,  1.68684750e+03,\n",
       "          2.86657414e+00,  2.92929293e-01,  1.04251534e+00,\n",
       "          6.40000000e+01,  1.00000000e+00,  1.65133333e+03,\n",
       "          1.66563407e-01],\n",
       "        [ 1.19100000e+03, -5.03000000e+02,  1.61056327e+03,\n",
       "         -3.69005508e+01,  5.76540755e-02,  1.38161209e+00,\n",
       "          5.03000000e+02,  1.00000000e+00,  1.35866667e+03,\n",
       "          5.99781936e-02],\n",
       "        [ 1.18500000e+03, -4.90000000e+02,  1.54509199e+03,\n",
       "         -6.81152435e+01,  0.00000000e+00,  1.33949367e+00,\n",
       "          4.90000000e+02,  1.00000000e+00,  1.34833333e+03,\n",
       "          3.89791220e-02],\n",
       "        [ 1.20500000e+03, -4.29000000e+02,  1.49277015e+03,\n",
       "         -9.01995157e+01,  4.08163265e-02,  1.27103734e+00,\n",
       "          4.49000000e+02,  9.55456570e-01,  1.34133333e+03,\n",
       "          7.02759361e-02],\n",
       "        [ 1.24500000e+03, -3.85000000e+02,  1.45465167e+03,\n",
       "         -1.03283210e+02,  1.33630290e-01,  1.19068273e+00,\n",
       "          4.45000000e+02,  8.65168539e-01,  1.35333333e+03,\n",
       "          1.05702304e-01],\n",
       "        [ 1.26400000e+03,  7.30000000e+01,  1.42532064e+03,\n",
       "         -1.10841282e+02,  1.77528090e-01,  1.13829114e+00,\n",
       "          7.90000000e+01,  0.00000000e+00,  1.23766667e+03,\n",
       "          1.52469077e-01],\n",
       "        [ 1.25400000e+03,  6.90000000e+01,  1.39896362e+03,\n",
       "         -1.16297420e+02,  4.93750000e+00,  1.11459330e+00,\n",
       "          7.90000000e+01,  1.26582278e-01,  1.23433333e+03,\n",
       "          1.69114026e-01],\n",
       "        [ 1.25400000e+03,  4.90000000e+01,  1.37666152e+03,\n",
       "         -1.19246846e+02,  7.90000000e+00,  1.07950558e+00,\n",
       "          5.90000000e+01,  1.69491525e-01,  1.24100000e+03,\n",
       "          1.55519575e-01],\n",
       "        [ 1.26000000e+03,  1.50000000e+01,  1.35871360e+03,\n",
       "         -1.19720078e+02,  6.50000000e+00,  1.04142857e+00,\n",
       "          1.90000000e+01,  2.10526316e-01,  1.25633333e+03,\n",
       "          2.02552988e-01],\n",
       "        [ 1.26400000e+03,  0.00000000e+00,  1.34414227e+03,\n",
       "         -1.18407425e+02,  2.90000000e+00,  1.00886076e+00,\n",
       "          1.00000000e+01,  0.00000000e+00,  1.26066667e+03,\n",
       "          2.17213283e-01],\n",
       "        [ 1.26500000e+03,  1.10000000e+01,  1.33196654e+03,\n",
       "         -1.15949848e+02,  1.10000000e+00,  9.79209486e-01,\n",
       "          1.10000000e+01,  0.00000000e+00,  1.26133333e+03,\n",
       "          2.29758037e-01],\n",
       "        [ 1.24500000e+03, -9.00000000e+00,  1.31858707e+03,\n",
       "         -1.14298473e+02,  5.50000000e-01,  9.99277108e-01,\n",
       "          2.00000000e+01,  1.00000000e+00,  1.25166667e+03,\n",
       "          1.92054081e-01],\n",
       "        [ 1.21800000e+03, -4.20000000e+01,  1.30311214e+03,\n",
       "         -1.13855959e+02,  2.34042553e-01,  1.02413793e+00,\n",
       "          4.70000000e+01,  1.00000000e+00,  1.23366667e+03,\n",
       "          1.33104166e-01],\n",
       "        [ 1.20500000e+03, -5.90000000e+01,  1.28801796e+03,\n",
       "         -1.13248793e+02,  8.33333333e-02,  1.03518672e+00,\n",
       "          6.00000000e+01,  1.00000000e+00,  1.22500000e+03,\n",
       "          2.55910028e-01],\n",
       "        [ 1.20500000e+03, -6.00000000e+01,  1.27524597e+03,\n",
       "         -1.11482510e+02,  1.66666667e-02,  1.03186722e+00,\n",
       "          6.00000000e+01,  1.00000000e+00,  1.22500000e+03,\n",
       "          2.53506804e-01],\n",
       "        [ 1.20000000e+03, -4.50000000e+01,  1.26366967e+03,\n",
       "         -1.09227073e+02,  0.00000000e+00,  1.03083333e+00,\n",
       "          4.50000000e+01,  1.00000000e+00,  1.21500000e+03,\n",
       "          2.21443640e-01],\n",
       "        [ 1.20000000e+03, -1.80000000e+01,  1.25387433e+03,\n",
       "         -1.06215241e+02,  0.00000000e+00,  1.02633333e+00,\n",
       "          1.80000000e+01,  1.00000000e+00,  1.20600000e+03,\n",
       "          1.14005785e-01],\n",
       "        [ 1.21900000e+03,  1.40000000e+01,  1.24850905e+03,\n",
       "         -1.01129443e+02,  1.05555556e+00,  1.00746514e+00,\n",
       "          1.90000000e+01,  0.00000000e+00,  1.21266667e+03,\n",
       "          1.40954331e-01],\n",
       "        [ 1.28500000e+03,  8.00000000e+01,  1.25412304e+03,\n",
       "         -9.07274142e+01,  1.70000000e+01,  9.57665370e-01,\n",
       "          8.50000000e+01,  0.00000000e+00,  1.25666667e+03,\n",
       "          4.40826373e-01],\n",
       "        [ 1.27300000e+03,  7.30000000e+01,  1.25702719e+03,\n",
       "         -8.25010109e+01,  5.00000000e+00,  9.67399843e-01,\n",
       "          8.50000000e+01,  1.41176471e-01,  1.25266667e+03,\n",
       "          5.17338039e-01],\n",
       "        [ 1.27700000e+03,  7.70000000e+01,  1.26009993e+03,\n",
       "         -7.47965523e+01,  7.41666667e+00,  9.65309319e-01,\n",
       "          8.50000000e+01,  9.41176471e-02,  1.25400000e+03,\n",
       "          4.95022249e-01],\n",
       "        [ 1.27200000e+03,  5.30000000e+01,  1.26193071e+03,\n",
       "         -6.83067736e+01,  5.23529412e+00,  9.71226415e-01,\n",
       "          6.60000000e+01,  1.96969697e-01,  1.25866667e+03,\n",
       "          4.89392947e-01],\n",
       "        [ 1.26500000e+03, -2.00000000e+01,  1.26240291e+03,\n",
       "         -6.30021689e+01,  2.91666667e+00,  9.80316206e-01,\n",
       "          2.00000000e+01,  1.00000000e+00,  1.27166667e+03,\n",
       "          4.53700765e-01]]), 0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1],y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fact = 0.1\n",
    "total = len(X)\n",
    "factor = int((total * (1-fact))/batch_size)*batch_size\n",
    "X_train, X_validate = X[:factor] , X[factor:int(total/batch_size)*batch_size] \n",
    "y_train, y_validate = y[:factor] , y[factor:int(total/batch_size)*batch_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NEURONS_FirstLayer = 128\n",
    "NUM_NEURONS_SecondLayer = 64\n",
    "EPOCHS = 220\n",
    "\n",
    "data_dim = 10\n",
    "#Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(NUM_NEURONS_FirstLayer,batch_input_shape=(batch_size,look_back,data_dim), return_sequences=True,stateful=True))\n",
    "model.add(LSTM(NUM_NEURONS_SecondLayer,stateful=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1148 samples, validate on 128 samples\n",
      "Epoch 1/220\n",
      " - 42s - loss: 0.7035 - acc: 0.5235 - val_loss: 0.6925 - val_acc: 0.5625\n",
      "Epoch 2/220\n",
      " - 56s - loss: 0.6955 - acc: 0.5305 - val_loss: 0.6910 - val_acc: 0.5625\n",
      "Epoch 3/220\n",
      " - 41s - loss: 0.6957 - acc: 0.5157 - val_loss: 0.6886 - val_acc: 0.5625\n",
      "Epoch 4/220\n",
      " - 41s - loss: 0.6895 - acc: 0.5505 - val_loss: 0.6885 - val_acc: 0.5625\n",
      "Epoch 5/220\n",
      " - 41s - loss: 0.6904 - acc: 0.5279 - val_loss: 0.6866 - val_acc: 0.5625\n",
      "Epoch 6/220\n",
      " - 42s - loss: 0.6930 - acc: 0.5235 - val_loss: 0.6884 - val_acc: 0.5625\n",
      "Epoch 7/220\n",
      " - 42s - loss: 0.6898 - acc: 0.5444 - val_loss: 0.6872 - val_acc: 0.5625\n",
      "Epoch 8/220\n",
      " - 42s - loss: 0.6899 - acc: 0.5314 - val_loss: 0.6858 - val_acc: 0.5625\n",
      "Epoch 9/220\n",
      " - 41s - loss: 0.6887 - acc: 0.5488 - val_loss: 0.6858 - val_acc: 0.5625\n",
      "Epoch 10/220\n",
      " - 43s - loss: 0.6882 - acc: 0.5497 - val_loss: 0.6855 - val_acc: 0.5625\n",
      "Epoch 11/220\n",
      " - 43s - loss: 0.6872 - acc: 0.5523 - val_loss: 0.6856 - val_acc: 0.5625\n",
      "Epoch 12/220\n",
      " - 43s - loss: 0.6871 - acc: 0.5549 - val_loss: 0.6868 - val_acc: 0.5625\n",
      "Epoch 13/220\n",
      " - 43s - loss: 0.6873 - acc: 0.5549 - val_loss: 0.6858 - val_acc: 0.5625\n",
      "Epoch 14/220\n",
      " - 46s - loss: 0.6852 - acc: 0.5540 - val_loss: 0.6858 - val_acc: 0.5625\n",
      "Epoch 15/220\n",
      " - 43s - loss: 0.6868 - acc: 0.5531 - val_loss: 0.6861 - val_acc: 0.5625\n",
      "Epoch 16/220\n",
      " - 44s - loss: 0.6867 - acc: 0.5540 - val_loss: 0.6864 - val_acc: 0.5625\n",
      "Epoch 17/220\n",
      " - 44s - loss: 0.6868 - acc: 0.5549 - val_loss: 0.6862 - val_acc: 0.5625\n",
      "Epoch 18/220\n",
      " - 44s - loss: 0.6857 - acc: 0.5557 - val_loss: 0.6859 - val_acc: 0.5625\n",
      "Epoch 19/220\n",
      " - 46s - loss: 0.6852 - acc: 0.5557 - val_loss: 0.6858 - val_acc: 0.5625\n",
      "Epoch 20/220\n",
      " - 45s - loss: 0.6847 - acc: 0.5557 - val_loss: 0.6857 - val_acc: 0.5625\n",
      "Epoch 21/220\n",
      " - 47s - loss: 0.6842 - acc: 0.5549 - val_loss: 0.6863 - val_acc: 0.5625\n",
      "Epoch 22/220\n",
      " - 49s - loss: 0.6849 - acc: 0.5566 - val_loss: 0.6861 - val_acc: 0.5625\n",
      "Epoch 23/220\n",
      " - 49s - loss: 0.6837 - acc: 0.5557 - val_loss: 0.6940 - val_acc: 0.5625\n",
      "Epoch 24/220\n",
      " - 49s - loss: 0.6845 - acc: 0.5549 - val_loss: 0.6894 - val_acc: 0.5625\n",
      "Epoch 25/220\n",
      " - 48s - loss: 0.6842 - acc: 0.5549 - val_loss: 0.6905 - val_acc: 0.5625\n",
      "Epoch 26/220\n",
      " - 49s - loss: 0.6856 - acc: 0.5557 - val_loss: 0.6892 - val_acc: 0.5625\n",
      "Epoch 27/220\n",
      " - 49s - loss: 0.6843 - acc: 0.5540 - val_loss: 0.6866 - val_acc: 0.5625\n",
      "Epoch 28/220\n",
      " - 50s - loss: 0.6824 - acc: 0.5557 - val_loss: 0.6910 - val_acc: 0.5625\n",
      "Epoch 29/220\n",
      " - 52s - loss: 0.6835 - acc: 0.5523 - val_loss: 0.6871 - val_acc: 0.5625\n",
      "Epoch 30/220\n",
      " - 51s - loss: 0.6830 - acc: 0.5592 - val_loss: 0.6886 - val_acc: 0.5625\n",
      "Epoch 31/220\n",
      " - 51s - loss: 0.6821 - acc: 0.5557 - val_loss: 0.6864 - val_acc: 0.5625\n",
      "Epoch 32/220\n",
      " - 54s - loss: 0.6853 - acc: 0.5566 - val_loss: 0.6858 - val_acc: 0.5625\n",
      "Epoch 33/220\n",
      " - 59s - loss: 0.6812 - acc: 0.5557 - val_loss: 0.6938 - val_acc: 0.5625\n",
      "Epoch 34/220\n",
      " - 49s - loss: 0.6823 - acc: 0.5540 - val_loss: 0.6882 - val_acc: 0.5625\n",
      "Epoch 35/220\n",
      " - 43s - loss: 0.6830 - acc: 0.5557 - val_loss: 0.6860 - val_acc: 0.5625\n",
      "Epoch 36/220\n",
      " - 40s - loss: 0.6820 - acc: 0.5566 - val_loss: 0.6935 - val_acc: 0.5625\n",
      "Epoch 37/220\n",
      " - 48s - loss: 0.6845 - acc: 0.5497 - val_loss: 0.6951 - val_acc: 0.5625\n",
      "Epoch 38/220\n",
      " - 48s - loss: 0.6823 - acc: 0.5618 - val_loss: 0.6863 - val_acc: 0.5625\n",
      "Epoch 39/220\n",
      " - 42s - loss: 0.6839 - acc: 0.5531 - val_loss: 0.6863 - val_acc: 0.5625\n",
      "Epoch 40/220\n",
      " - 45s - loss: 0.6851 - acc: 0.5523 - val_loss: 0.6872 - val_acc: 0.5625\n",
      "Epoch 41/220\n",
      " - 58s - loss: 0.6839 - acc: 0.5549 - val_loss: 0.6859 - val_acc: 0.5625\n",
      "Epoch 42/220\n",
      " - 41s - loss: 0.6831 - acc: 0.5575 - val_loss: 0.6861 - val_acc: 0.5625\n",
      "Epoch 43/220\n",
      " - 44s - loss: 0.6822 - acc: 0.5549 - val_loss: 0.6963 - val_acc: 0.5625\n",
      "Epoch 44/220\n",
      " - 41s - loss: 0.6846 - acc: 0.5566 - val_loss: 0.6862 - val_acc: 0.5625\n",
      "Epoch 45/220\n",
      " - 41s - loss: 0.6827 - acc: 0.5540 - val_loss: 0.6860 - val_acc: 0.5625\n",
      "Epoch 46/220\n",
      " - 45s - loss: 0.6834 - acc: 0.5549 - val_loss: 0.6870 - val_acc: 0.5625\n",
      "Epoch 47/220\n",
      " - 42s - loss: 0.6842 - acc: 0.5557 - val_loss: 0.6895 - val_acc: 0.5625\n",
      "Epoch 48/220\n",
      " - 44s - loss: 0.6827 - acc: 0.5557 - val_loss: 0.6897 - val_acc: 0.5625\n",
      "Epoch 49/220\n",
      " - 41s - loss: 0.6826 - acc: 0.5523 - val_loss: 0.6988 - val_acc: 0.5625\n",
      "Epoch 50/220\n",
      " - 41s - loss: 0.6842 - acc: 0.5566 - val_loss: 0.6890 - val_acc: 0.5625\n",
      "Epoch 51/220\n",
      " - 53s - loss: 0.6834 - acc: 0.5592 - val_loss: 0.6875 - val_acc: 0.5625\n",
      "Epoch 52/220\n",
      " - 42s - loss: 0.6813 - acc: 0.5566 - val_loss: 0.6912 - val_acc: 0.5625\n",
      "Epoch 53/220\n",
      " - 41s - loss: 0.6834 - acc: 0.5531 - val_loss: 0.6868 - val_acc: 0.5625\n",
      "Epoch 54/220\n",
      " - 41s - loss: 0.6816 - acc: 0.5575 - val_loss: 0.6869 - val_acc: 0.5625\n",
      "Epoch 55/220\n",
      " - 41s - loss: 0.6852 - acc: 0.5557 - val_loss: 0.6946 - val_acc: 0.5625\n",
      "Epoch 56/220\n",
      " - 58s - loss: 0.6839 - acc: 0.5531 - val_loss: 0.6871 - val_acc: 0.5625\n",
      "Epoch 57/220\n",
      " - 41s - loss: 0.6838 - acc: 0.5575 - val_loss: 0.6910 - val_acc: 0.5625\n",
      "Epoch 58/220\n",
      " - 44s - loss: 0.6828 - acc: 0.5523 - val_loss: 0.6889 - val_acc: 0.5625\n",
      "Epoch 59/220\n",
      " - 46s - loss: 0.6819 - acc: 0.5523 - val_loss: 0.6866 - val_acc: 0.5625\n",
      "Epoch 60/220\n",
      " - 41s - loss: 0.6823 - acc: 0.5523 - val_loss: 0.6880 - val_acc: 0.5625\n",
      "Epoch 61/220\n",
      " - 42s - loss: 0.6818 - acc: 0.5566 - val_loss: 0.6872 - val_acc: 0.5625\n",
      "Epoch 62/220\n",
      " - 42s - loss: 0.6833 - acc: 0.5575 - val_loss: 0.6872 - val_acc: 0.5625\n",
      "Epoch 63/220\n",
      " - 44s - loss: 0.6810 - acc: 0.5566 - val_loss: 0.6871 - val_acc: 0.5625\n",
      "Epoch 64/220\n",
      " - 41s - loss: 0.6846 - acc: 0.5557 - val_loss: 0.6880 - val_acc: 0.5625\n",
      "Epoch 65/220\n",
      " - 42s - loss: 0.6840 - acc: 0.5566 - val_loss: 0.6883 - val_acc: 0.5625\n",
      "Epoch 66/220\n",
      " - 39s - loss: 0.6832 - acc: 0.5592 - val_loss: 0.6886 - val_acc: 0.5625\n",
      "Epoch 67/220\n",
      " - 49s - loss: 0.6847 - acc: 0.5557 - val_loss: 0.6914 - val_acc: 0.5625\n",
      "Epoch 68/220\n",
      " - 46s - loss: 0.6854 - acc: 0.5557 - val_loss: 0.6867 - val_acc: 0.5625\n",
      "Epoch 69/220\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=EPOCHS,validation_data=(X_validate,y_validate),shuffle=False,batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "PartialTensorShape: Incompatible shapes during merge: [32,128] vs. [1,128]\n\t [[{{node lstm_45/TensorArrayStack/TensorArrayGatherV3}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-c3516be4abe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: PartialTensorShape: Incompatible shapes during merge: [32,128] vs. [1,128]\n\t [[{{node lstm_45/TensorArrayStack/TensorArrayGatherV3}}]]"
     ]
    }
   ],
   "source": [
    "model.predict(X_validate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
