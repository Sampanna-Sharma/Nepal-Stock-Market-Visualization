{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1940e975410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import ast\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing to include label and shift it one place up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "nepse_data = pd.read_csv(\"data_set_ready_for_training.csv\")\n",
    "nepse_data[\"news\"] = nepse_data[\"news\"].apply(ast.literal_eval)\n",
    "#nepse_data.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closing_price</th>\n",
       "      <th>news</th>\n",
       "      <th>momentum</th>\n",
       "      <th>EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ROI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>williams</th>\n",
       "      <th>CCI</th>\n",
       "      <th>UO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975.0</td>\n",
       "      <td>[[0.2306930273771286, 0.792356550693512, 0.642...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>1087.863864</td>\n",
       "      <td>-58.947313</td>\n",
       "      <td>0.149378</td>\n",
       "      <td>1.126154</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>997.666667</td>\n",
       "      <td>0.154372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>954.0</td>\n",
       "      <td>[[0.31689509749412537, 0.8638337850570679, 0.6...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1067.269422</td>\n",
       "      <td>-65.253876</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.122642</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>966.666667</td>\n",
       "      <td>0.105707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917.0</td>\n",
       "      <td>[[0.31150949001312256, 0.7647785544395447, 0.6...</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>1044.151049</td>\n",
       "      <td>-72.401798</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.135878</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>0.069584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>903.0</td>\n",
       "      <td>[[0.1868913620710373, 0.7952941060066223, 0.61...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>1022.435502</td>\n",
       "      <td>-78.293327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.120598</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>0.068895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>885.0</td>\n",
       "      <td>[[0.3303453326225281, 0.8576347231864929, 0.68...</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1001.291578</td>\n",
       "      <td>-83.452392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.108927</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>0.108076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897.0</td>\n",
       "      <td>[[0.20605844259262085, 0.858686089515686, 0.64...</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>985.246720</td>\n",
       "      <td>-85.586305</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.062542</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>912.000000</td>\n",
       "      <td>0.117757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>947.0</td>\n",
       "      <td>[[0.2074199914932251, 0.7867178320884705, 0.59...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>979.362609</td>\n",
       "      <td>-82.295166</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.994298</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>926.333333</td>\n",
       "      <td>0.204783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>910.0</td>\n",
       "      <td>[[0.42128807306289673, 0.7513155937194824, 0.6...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>968.691438</td>\n",
       "      <td>-81.729667</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>1.029670</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>914.000000</td>\n",
       "      <td>0.203104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>925.0</td>\n",
       "      <td>[[0.3032321333885193, 0.9355986714363098, 0.52...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>961.969678</td>\n",
       "      <td>-79.158862</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.005730</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>919.000000</td>\n",
       "      <td>0.194369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>900.0</td>\n",
       "      <td>[[0.17515438795089722, 0.8498166799545288, 0.7...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>952.435882</td>\n",
       "      <td>-78.236491</td>\n",
       "      <td>1.241935</td>\n",
       "      <td>1.023667</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>914.666667</td>\n",
       "      <td>0.205341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closing_price                                               news  momentum  \\\n",
       "0          975.0  [[0.2306930273771286, 0.792356550693512, 0.642...     -87.0   \n",
       "1          954.0  [[0.31689509749412537, 0.8638337850570679, 0.6...      -2.0   \n",
       "2          917.0  [[0.31150949001312256, 0.7647785544395447, 0.6...     -75.0   \n",
       "3          903.0  [[0.1868913620710373, 0.7952941060066223, 0.61...     -87.0   \n",
       "4          885.0  [[0.3303453326225281, 0.8576347231864929, 0.68...     -90.0   \n",
       "5          897.0  [[0.20605844259262085, 0.858686089515686, 0.64...     -57.0   \n",
       "6          947.0  [[0.2074199914932251, 0.7867178320884705, 0.59...      30.0   \n",
       "7          910.0  [[0.42128807306289673, 0.7513155937194824, 0.6...       7.0   \n",
       "8          925.0  [[0.3032321333885193, 0.9355986714363098, 0.52...      40.0   \n",
       "9          900.0  [[0.17515438795089722, 0.8498166799545288, 0.7...       3.0   \n",
       "\n",
       "           EMA       MACD       RSI       ROI    ATR  williams         CCI  \\\n",
       "0  1087.863864 -58.947313  0.149378  1.126154  106.0  0.820755  997.666667   \n",
       "1  1067.269422 -65.253876  0.250000  1.122642   38.0  1.000000  966.666667   \n",
       "2  1044.151049 -72.401798  0.480000  1.135878   75.0  1.000000  942.000000   \n",
       "3  1022.435502 -78.293327  0.000000  1.120598   87.0  1.000000  932.000000   \n",
       "4  1001.291578 -83.452392  0.000000  1.108927   90.0  1.000000  915.000000   \n",
       "5   985.246720 -85.586305  0.133333  1.062542   69.0  0.826087  912.000000   \n",
       "6   979.362609 -82.295166  0.898551  0.994298   62.0  0.000000  926.333333   \n",
       "7   968.691438 -81.729667  0.898551  1.029670   62.0  0.596774  914.000000   \n",
       "8   961.969678 -79.158862  1.400000  1.005730   62.0  0.354839  919.000000   \n",
       "9   952.435882 -78.236491  1.241935  1.023667   50.0  0.940000  914.666667   \n",
       "\n",
       "         UO  \n",
       "0  0.154372  \n",
       "1  0.105707  \n",
       "2  0.069584  \n",
       "3  0.068895  \n",
       "4  0.108076  \n",
       "5  0.117757  \n",
       "6  0.204783  \n",
       "7  0.203104  \n",
       "8  0.194369  \n",
       "9  0.205341  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepse_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepse_data['Label'] = nepse_data['closing_price'].rolling(window=2).apply(lambda x:  1 if x[1]>x[0] else 0 )\n",
    "nepse_data.Label = nepse_data.Label.shift(-1)\n",
    "nepse_data = nepse_data[:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here on, data is prepared to be fed to pytorch network\n",
    "\n",
    "The dataset is prepared by inheriting Dataset class, and DataLoader class is used for batching. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader class\n",
    "class NepseDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.features = dataset.loc[:, 'momentum':'CCI'].as_matrix()\n",
    "        self.label =  dataset['Label'].as_matrix()\n",
    "        self.news = dataset['news'].as_matrix()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tech_indicators = self.features[idx,:]\n",
    "        label = self.label[idx]\n",
    "        news = self.news[idx]\n",
    "        sample = {'news': news,'tech_indicators': tech_indicators, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        news, tech_indicators, label = sample['news'], sample['tech_indicators'], sample['label']\n",
    "\n",
    "        return {'news': torch.FloatTensor(news),\n",
    "                'tech_indicators': torch.from_numpy(tech_indicators).float(),\n",
    "                'label': int(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_zeros(news):\n",
    "    padding_dims = 30 - len(news)\n",
    "    for _ in range(padding_dims):\n",
    "        news.append([0]*100)\n",
    "    return news\n",
    "def truncate(news):\n",
    "    return news[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(nepse_data.news)\n",
    "for i in range(len(nepse_data.news)):\n",
    "    \n",
    "    if len(nepse_data.news[i])<30:\n",
    "        nepse_data.news[i] = append_zeros(nepse_data.news[i])\n",
    "    elif len(nepse_data.news[i])>30:\n",
    "        nepse_data.news[i] = truncate(nepse_data.news[i])\n",
    "        \n",
    "\n",
    "test_data = NepseDataset(nepse_data, transform=ToTensor())\n",
    "print(len(test_data))\n",
    "test_data[0]['news'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(test_data, batch_size=10)\n",
    "for i, sample in enumerate(data):\n",
    "    print(sample['news'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Neural Network\n",
    " The network consists of CNN which extracts features from news, the output of which is concatenated with the technical indicators and fed to lstm. The output is then fed to softmax to predict the rise or fall in nepse for the following day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class StockNN(nn.Module):\n",
    "    def __init__(self, filter_sizes, drop_prob, embedding_dim, length_of_features, n_hidden_lstm=256, n_layers=1):\n",
    "        super(StockNN, self).__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv1d(in_channels = 1, \n",
    "                                              out_channels = 2, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        self.lstm = nn.LSTM(length_of_features, n_hidden_lstm, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.linear = nn.Linear(n_hidden_lstm, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        \n",
    "        x_cnn = x['news']\n",
    "        x_cnn = x_cnn.reshape(x_cnn.shape[0],1,x_cnn.shape[1], x_cnn.shape[2])\n",
    "        conved = [F.relu(conv(x_cnn)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        stock_features = self.dropout(torch.cat(pooled, dim = 1).squeeze())\n",
    "        \n",
    "        stock_features = torch.cat([stock_features,x['tech_indicators']], dim=1)\n",
    "        out, (h,c) = self.lstm(stock_features.view(stock_features.shape[0],1,-1),h)\n",
    "        hidden_2_risefall = self.dropout(self.linear(out.view(out.shape[0],-1)))\n",
    "        rise_fall = F.softmax(hidden_2_risefall, dim=1)\n",
    "        \n",
    "        return rise_fall, (h,c)\n",
    "    \n",
    "    def init_hidden(self, n_seqs):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(1, n_seqs, 256).zero_(),\n",
    "                weight.new(1, n_seqs, 256).zero_())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1239 138\n"
     ]
    }
   ],
   "source": [
    "def train_validate_set(data,val_frac=0.1):\n",
    "    m = data.shape[0]\n",
    "    val_idx = int(m*(1-val_frac))\n",
    "    test_data, val_data = NepseDataset(data.head(val_idx),ToTensor()), NepseDataset(data.tail(m - val_idx),ToTensor())\n",
    "    return test_data, val_data\n",
    "\n",
    "td, vd = train_validate_set(nepse_data) \n",
    "print(len(td), len(vd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the StockNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have to check this one\n",
    "def train(NN, data, val_frac=0.2, max_epochs=10, batch_size=10, learning_rate=0.001):\n",
    "    NN.train()\n",
    "    opt = torch.optim.Adam(NN.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    train_data, validate_data = train_validate_set(data,val_frac)\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    for e in range(max_epochs):\n",
    "        h = NN.init_hidden(batch_size)\n",
    "        \n",
    "        for i_batch, batched_sample in enumerate(dataloader):\n",
    "            h = tuple([each.data for each in h])\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            xtrain = {key: batched_sample.get(key) for key in batched_sample if key == 'news' or key == 'tech_indicators'}\n",
    "            out, h= NN(xtrain,h)\n",
    "            loss = criterion(out,batched_sample['label'])\n",
    "            loss.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            print(e, i_batch, loss.item())\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.Tensor([[1,2,3],[5,9,6]])\n",
    "d2 = torch.Tensor([[4,5,6,7],[0,8,9,4]])\n",
    "torch.cat([d1,d2],dim=1)\n",
    "np.multiply(*d1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_net = StockNN([2,3,4], 0.5, 100, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.675051212310791\n",
      "0 1 0.7055670022964478\n",
      "0 2 0.7940192818641663\n",
      "0 3 0.772091269493103\n",
      "0 4 0.6749516725540161\n",
      "0 5 0.6558800935745239\n",
      "0 6 0.6484292149543762\n",
      "0 7 0.6340871453285217\n",
      "0 8 0.6128209829330444\n",
      "0 9 0.8438916802406311\n",
      "0 10 nan\n",
      "0 11 nan\n",
      "0 12 nan\n",
      "0 13 nan\n",
      "0 14 nan\n",
      "0 15 nan\n",
      "0 16 nan\n",
      "0 17 nan\n",
      "0 18 nan\n",
      "0 19 nan\n",
      "0 20 nan\n",
      "0 21 nan\n",
      "0 22 nan\n",
      "0 23 nan\n",
      "0 24 nan\n",
      "0 25 nan\n",
      "0 26 nan\n",
      "0 27 nan\n",
      "0 28 nan\n",
      "0 29 nan\n",
      "0 30 nan\n",
      "0 31 nan\n",
      "0 32 nan\n",
      "0 33 nan\n",
      "0 34 nan\n",
      "0 35 nan\n",
      "0 36 nan\n",
      "0 37 nan\n",
      "0 38 nan\n",
      "0 39 nan\n",
      "0 40 nan\n",
      "0 41 nan\n",
      "0 42 nan\n",
      "0 43 nan\n",
      "0 44 nan\n",
      "0 45 nan\n",
      "0 46 nan\n",
      "0 47 nan\n",
      "0 48 nan\n",
      "0 49 nan\n",
      "0 50 nan\n",
      "0 51 nan\n",
      "0 52 nan\n",
      "0 53 nan\n",
      "0 54 nan\n",
      "0 55 nan\n",
      "0 56 nan\n",
      "0 57 nan\n",
      "0 58 nan\n",
      "0 59 nan\n",
      "0 60 nan\n",
      "0 61 nan\n",
      "0 62 nan\n",
      "0 63 nan\n",
      "0 64 nan\n",
      "0 65 nan\n",
      "0 66 nan\n",
      "0 67 nan\n",
      "0 68 nan\n",
      "0 69 nan\n",
      "0 70 nan\n",
      "0 71 nan\n",
      "0 72 nan\n",
      "0 73 nan\n",
      "0 74 nan\n",
      "0 75 nan\n",
      "0 76 nan\n",
      "0 77 nan\n",
      "0 78 nan\n",
      "0 79 nan\n",
      "0 80 nan\n",
      "0 81 nan\n",
      "0 82 nan\n",
      "0 83 nan\n",
      "0 84 nan\n",
      "0 85 nan\n",
      "0 86 nan\n",
      "0 87 nan\n",
      "0 88 nan\n",
      "0 89 nan\n",
      "0 90 nan\n",
      "0 91 nan\n",
      "0 92 nan\n",
      "0 93 nan\n",
      "0 94 nan\n",
      "0 95 nan\n",
      "0 96 nan\n",
      "0 97 nan\n",
      "0 98 nan\n",
      "0 99 nan\n",
      "0 100 nan\n",
      "0 101 nan\n",
      "0 102 nan\n",
      "0 103 nan\n",
      "0 104 nan\n",
      "0 105 nan\n",
      "0 106 nan\n",
      "0 107 nan\n",
      "0 108 nan\n",
      "0 109 nan\n",
      "0 110 nan\n",
      "0 111 nan\n",
      "0 112 nan\n",
      "0 113 nan\n",
      "0 114 nan\n",
      "0 115 nan\n",
      "0 116 nan\n",
      "0 117 nan\n",
      "0 118 nan\n",
      "0 119 nan\n",
      "0 120 nan\n",
      "0 121 nan\n",
      "0 122 nan\n",
      "0 123 nan\n",
      "0 124 nan\n",
      "0 125 nan\n",
      "0 126 nan\n",
      "0 127 nan\n",
      "0 128 nan\n",
      "0 129 nan\n",
      "0 130 nan\n",
      "0 131 nan\n",
      "0 132 nan\n",
      "0 133 nan\n",
      "0 134 nan\n",
      "0 135 nan\n",
      "0 136 nan\n",
      "0 137 nan\n",
      "0 138 nan\n",
      "0 139 nan\n",
      "0 140 nan\n",
      "0 141 nan\n",
      "0 142 nan\n",
      "0 143 nan\n",
      "0 144 nan\n",
      "0 145 nan\n",
      "0 146 nan\n",
      "0 147 nan\n",
      "0 148 nan\n",
      "0 149 nan\n",
      "0 150 nan\n",
      "0 151 nan\n",
      "0 152 nan\n",
      "0 153 nan\n",
      "0 154 nan\n",
      "0 155 nan\n",
      "0 156 nan\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 2, 256), got (1, 7, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-328-786fd3d496c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnepse_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-325-5a5457891a1a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(NN, data, val_frac, max_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mxtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatched_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatched_sample\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'news'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tech_indicators'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatched_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-323-beda600b0e71>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, h)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mstock_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstock_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tech_indicators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mhidden_2_risefall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mrise_fall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_2_risefall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LSTM'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[1;32m--> 152\u001b[1;33m                               'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[0;32m    153\u001b[0m             check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[0;32m    154\u001b[0m                               'Expected hidden[1] size {}, got {}')\n",
      "\u001b[1;32mc:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[1;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LSTM'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 2, 256), got (1, 7, 256)"
     ]
    }
   ],
   "source": [
    "\n",
    "train(stock_net, nepse_data, max_epochs= 10, batch_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
