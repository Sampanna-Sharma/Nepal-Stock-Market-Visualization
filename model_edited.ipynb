{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2192bd73510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import ast\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing to include label and shift it one place up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "nepse_data = pd.read_csv(\"data_set_ready_for_training.csv\")\n",
    "nepse_data[\"news\"] = nepse_data[\"news\"].apply(ast.literal_eval)\n",
    "#nepse_data.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1318 entries, 0 to 1377\n",
      "Data columns (total 11 columns):\n",
      "closing_price    1318 non-null float64\n",
      "news             1318 non-null object\n",
      "momentum         1318 non-null float64\n",
      "EMA              1318 non-null float64\n",
      "MACD             1318 non-null float64\n",
      "RSI              1318 non-null float64\n",
      "ROI              1318 non-null float64\n",
      "ATR              1318 non-null float64\n",
      "williams         1318 non-null float64\n",
      "CCI              1318 non-null float64\n",
      "UO               1318 non-null float64\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 123.6+ KB\n"
     ]
    }
   ],
   "source": [
    "nepse_data = nepse_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "nepse_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closing_price</th>\n",
       "      <th>news</th>\n",
       "      <th>momentum</th>\n",
       "      <th>EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ROI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>williams</th>\n",
       "      <th>CCI</th>\n",
       "      <th>UO</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975.0</td>\n",
       "      <td>[[0.2306930273771286, 0.792356550693512, 0.642...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>1087.863864</td>\n",
       "      <td>-58.947313</td>\n",
       "      <td>0.149378</td>\n",
       "      <td>1.126154</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>997.666667</td>\n",
       "      <td>0.154372</td>\n",
       "      <td>954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>954.0</td>\n",
       "      <td>[[0.31689509749412537, 0.8638337850570679, 0.6...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1067.269422</td>\n",
       "      <td>-65.253876</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.122642</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>966.666667</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917.0</td>\n",
       "      <td>[[0.31150949001312256, 0.7647785544395447, 0.6...</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>1044.151049</td>\n",
       "      <td>-72.401798</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.135878</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>0.069584</td>\n",
       "      <td>903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>903.0</td>\n",
       "      <td>[[0.1868913620710373, 0.7952941060066223, 0.61...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>1022.435502</td>\n",
       "      <td>-78.293327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.120598</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>885.0</td>\n",
       "      <td>[[0.3303453326225281, 0.8576347231864929, 0.68...</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1001.291578</td>\n",
       "      <td>-83.452392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.108927</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>0.108076</td>\n",
       "      <td>897.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closing_price                                               news  momentum  \\\n",
       "0          975.0  [[0.2306930273771286, 0.792356550693512, 0.642...     -87.0   \n",
       "1          954.0  [[0.31689509749412537, 0.8638337850570679, 0.6...      -2.0   \n",
       "2          917.0  [[0.31150949001312256, 0.7647785544395447, 0.6...     -75.0   \n",
       "3          903.0  [[0.1868913620710373, 0.7952941060066223, 0.61...     -87.0   \n",
       "4          885.0  [[0.3303453326225281, 0.8576347231864929, 0.68...     -90.0   \n",
       "\n",
       "           EMA       MACD       RSI       ROI    ATR  williams         CCI  \\\n",
       "0  1087.863864 -58.947313  0.149378  1.126154  106.0  0.820755  997.666667   \n",
       "1  1067.269422 -65.253876  0.250000  1.122642   38.0  1.000000  966.666667   \n",
       "2  1044.151049 -72.401798  0.480000  1.135878   75.0  1.000000  942.000000   \n",
       "3  1022.435502 -78.293327  0.000000  1.120598   87.0  1.000000  932.000000   \n",
       "4  1001.291578 -83.452392  0.000000  1.108927   90.0  1.000000  915.000000   \n",
       "\n",
       "         UO  Label  \n",
       "0  0.154372  954.0  \n",
       "1  0.105707  917.0  \n",
       "2  0.069584  903.0  \n",
       "3  0.068895  885.0  \n",
       "4  0.108076  897.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nepse_data['Label'] = nepse_data['closing_price'].rolling(window=2).apply(lambda x:  1 if x[1]>x[0] else 0 )\n",
    "nepse_data['Label'] = nepse_data['closing_price'].shift(-1)\n",
    "#nepse_data.Label = nepse_data.Label.shift(-1)\n",
    "nepse_data = nepse_data[:-1]\n",
    "nepse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closing_price</th>\n",
       "      <th>momentum</th>\n",
       "      <th>EMA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ROI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>williams</th>\n",
       "      <th>CCI</th>\n",
       "      <th>UO</th>\n",
       "      <th>news</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.769629</td>\n",
       "      <td>-0.751830</td>\n",
       "      <td>-1.547293</td>\n",
       "      <td>-1.100855</td>\n",
       "      <td>-0.331177</td>\n",
       "      <td>2.667207</td>\n",
       "      <td>0.160012</td>\n",
       "      <td>0.727474</td>\n",
       "      <td>-1.725909</td>\n",
       "      <td>-1.280679</td>\n",
       "      <td>[[0.2306930273771286, 0.792356550693512, 0.642...</td>\n",
       "      <td>954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.816039</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>-1.593452</td>\n",
       "      <td>-1.219465</td>\n",
       "      <td>-0.319227</td>\n",
       "      <td>2.591076</td>\n",
       "      <td>-0.296228</td>\n",
       "      <td>1.158930</td>\n",
       "      <td>-1.794748</td>\n",
       "      <td>-1.462921</td>\n",
       "      <td>[[0.31689509749412537, 0.8638337850570679, 0.6...</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.897810</td>\n",
       "      <td>-0.644206</td>\n",
       "      <td>-1.645269</td>\n",
       "      <td>-1.353898</td>\n",
       "      <td>-0.291911</td>\n",
       "      <td>2.877979</td>\n",
       "      <td>-0.047980</td>\n",
       "      <td>1.158930</td>\n",
       "      <td>-1.849524</td>\n",
       "      <td>-1.598194</td>\n",
       "      <td>[[0.31150949001312256, 0.7647785544395447, 0.6...</td>\n",
       "      <td>903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.928751</td>\n",
       "      <td>-0.751830</td>\n",
       "      <td>-1.693941</td>\n",
       "      <td>-1.464702</td>\n",
       "      <td>-0.348918</td>\n",
       "      <td>2.546782</td>\n",
       "      <td>0.032533</td>\n",
       "      <td>1.158930</td>\n",
       "      <td>-1.871730</td>\n",
       "      <td>-1.600776</td>\n",
       "      <td>[[0.1868913620710373, 0.7952941060066223, 0.61...</td>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.968531</td>\n",
       "      <td>-0.778736</td>\n",
       "      <td>-1.741331</td>\n",
       "      <td>-1.561730</td>\n",
       "      <td>-0.348918</td>\n",
       "      <td>2.293798</td>\n",
       "      <td>0.052661</td>\n",
       "      <td>1.158930</td>\n",
       "      <td>-1.909481</td>\n",
       "      <td>-1.454049</td>\n",
       "      <td>[[0.3303453326225281, 0.8576347231864929, 0.68...</td>\n",
       "      <td>897.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closing_price  momentum       EMA      MACD       RSI       ROI       ATR  \\\n",
       "0      -1.769629 -0.751830 -1.547293 -1.100855 -0.331177  2.667207  0.160012   \n",
       "1      -1.816039  0.010508 -1.593452 -1.219465 -0.319227  2.591076 -0.296228   \n",
       "2      -1.897810 -0.644206 -1.645269 -1.353898 -0.291911  2.877979 -0.047980   \n",
       "3      -1.928751 -0.751830 -1.693941 -1.464702 -0.348918  2.546782  0.032533   \n",
       "4      -1.968531 -0.778736 -1.741331 -1.561730 -0.348918  2.293798  0.052661   \n",
       "\n",
       "   williams       CCI        UO  \\\n",
       "0  0.727474 -1.725909 -1.280679   \n",
       "1  1.158930 -1.794748 -1.462921   \n",
       "2  1.158930 -1.849524 -1.598194   \n",
       "3  1.158930 -1.871730 -1.600776   \n",
       "4  1.158930 -1.909481 -1.454049   \n",
       "\n",
       "                                                news  Label  \n",
       "0  [[0.2306930273771286, 0.792356550693512, 0.642...  954.0  \n",
       "1  [[0.31689509749412537, 0.8638337850570679, 0.6...  917.0  \n",
       "2  [[0.31150949001312256, 0.7647785544395447, 0.6...  903.0  \n",
       "3  [[0.1868913620710373, 0.7952941060066223, 0.61...  885.0  \n",
       "4  [[0.3303453326225281, 0.8576347231864929, 0.68...  897.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  nepse_data.loc[:,[\"closing_price\", \"momentum\",\"EMA\",\"MACD\",\"RSI\",\"ROI\",\"ATR\",\"williams\",\n",
    "                                \"CCI\",\"UO\"]]\n",
    "normalizer = StandardScaler()\n",
    "normalizer.fit(test.values)\n",
    "x_norm = pd.DataFrame(normalizer.transform(test.values), index=test.index, columns=test.columns)\n",
    "x_norm\n",
    "x_norm[\"news\"] = nepse_data[\"news\"]\n",
    "x_norm[\"Label\"] = nepse_data[\"Label\"]\n",
    "x_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here on, data is prepared to be fed to pytorch network\n",
    "\n",
    "The dataset is prepared by inheriting Dataset class, and DataLoader class is used for batching. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader class\n",
    "class NepseDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.features = dataset.loc[:, [\"closing_price\", \"momentum\",\"EMA\",\"MACD\",\"RSI\",\"ROI\",\"ATR\",\"williams\",\n",
    "                                \"CCI\",\"UO\"]].values\n",
    "        self.label =  dataset['Label'].values\n",
    "        self.news = dataset['news'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tech_indicators = self.features[idx,:]\n",
    "        label = self.label[idx]\n",
    "        news = self.news[idx]\n",
    "        sample = {'news': torch.tensor(news),'tech_indicators': torch.tensor(tech_indicators)\n",
    "                  ,'label': torch.tensor(label)}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_zeros(news):\n",
    "    padding_dims = 20 - len(news)\n",
    "    for _ in range(padding_dims):\n",
    "        news.append([0]*100)\n",
    "    return news\n",
    "def truncate(news):\n",
    "    return news[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_dimens(news):  \n",
    "    if len(news)<20:\n",
    "        news = append_zeros(news)\n",
    "    elif len(news)>20:\n",
    "        news = truncate(news)\n",
    "    \n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm[\"news\"] = x_norm[\"news\"].apply(const_dimens)\n",
    "\n",
    "test_data = NepseDataset(x_norm)\n",
    "print(len(test_data))\n",
    "test_data[0]['news'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news': tensor([[[ 0.2307,  0.7924,  0.6421,  ..., -0.2635,  0.2692, -0.0625],\n",
      "         [ 0.4144,  0.8800,  0.7002,  ..., -0.3542,  0.0610, -0.1523],\n",
      "         [ 0.4557,  0.9929,  0.7184,  ..., -0.3667,  0.0949, -0.2086],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]), 'tech_indicators': tensor([[-1.7696, -0.7518, -1.5473, -1.1009, -0.3312,  2.6672,  0.1600,  0.7275,\n",
      "         -1.7259, -1.2807]], dtype=torch.float64), 'label': tensor([954.])}\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(test_data, batch_size=1)\n",
    "for i, sample in enumerate(data):\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,4)\n",
    "b = torch.randn(3,6)\n",
    "torch.cat((a,b),dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Neural Network\n",
    " The network consists of CNN which extracts features from news, the output of which is concatenated with the technical indicators and fed to lstm. The output is then fed to softmax to predict the rise or fall in nepse for the following day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class StockNN(nn.Module):\n",
    "    def __init__(self, filter_sizes, drop_prob, embedding_dim, length_of_features, n_hidden_lstm=256, n_layers=1):\n",
    "        super(StockNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden_lstm = n_hidden_lstm\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = 1, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        self.lstm = nn.LSTM(length_of_features, n_hidden_lstm, n_layers, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(n_hidden_lstm)\n",
    "        self.linear = nn.Linear(n_hidden_lstm, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,hc):\n",
    "        \n",
    "        #x_cnn = x['news']\n",
    "        #x_cnn = x_cnn.reshape(x_cnn.shape[0],1,x_cnn.shape[1], x_cnn.shape[2])\n",
    "        #print(x_cnn.shape)\n",
    "        #conved = [F.relu(conv(x_cnn)).squeeze(3) for conv in self.convs]\n",
    "        #print(x.shape for x in list(conved))\n",
    "        #pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        #print(x.shape for x in list(pooled))\n",
    "        #stock_features = torch.cat(pooled, dim = 1)\n",
    "        #print(stock_features.shape)\n",
    "        #print(x['tech_indicators'].shape)\n",
    "        \n",
    "        #stock_features = torch.cat([stock_features,x['tech_indicators'].float()], dim=1)\n",
    "        stock_features = x['tech_indicators'].float()\n",
    "        #print(stock_features.shape)\n",
    "        out, (h,c) = self.lstm(stock_features.view(stock_features.shape[0],1,-1),hc)\n",
    "        #out = self.batch_norm(out.view(out.shape[0],-1))\n",
    "        hidden_2_risefall = self.linear(out.view(out.shape[0],-1))\n",
    "        rise_fall = F.relu(hidden_2_risefall)\n",
    "        \n",
    "        return rise_fall, (h,c)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.n_hidden_lstm),\n",
    "                torch.zeros(self.n_layers, batch_size, self.n_hidden_lstm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053 264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_validate_set(data,val_frac=0):\n",
    "    m = data.shape[0]\n",
    "    val_idx = int(m*(1-val_frac))\n",
    "    test_data, val_data = NepseDataset(data.head(val_idx)), NepseDataset(data.tail(m - val_idx))\n",
    "    return test_data, val_data\n",
    "\n",
    "td, vd = train_validate_set(nepse_data,0.2) \n",
    "print(len(td), len(vd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the StockNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have to check this one\n",
    "def train(NN, data, val_frac=0.2, max_epochs=10, batch_size=10, learning_rate=1e-3):\n",
    "    last_loss = 100\n",
    "    NN.train()\n",
    "    opt = torch.optim.Adam(NN.parameters(),lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    train_data, validate_data = train_validate_set(data,val_frac)\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    for e in range(max_epochs):\n",
    "        hc = NN.init_hidden(batch_size)\n",
    "        \n",
    "        for i_batch, batched_sample in enumerate(dataloader):\n",
    "            if len(batched_sample['label']) < batch_size:\n",
    "                continue\n",
    "            xtrain = dict(news = batched_sample[\"news\"],tech_indicators = batched_sample['tech_indicators'])\n",
    "            out, hc= NN(xtrain,hc)\n",
    "        \n",
    "            loss = criterion(out,batched_sample['label'].float())\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            opt.step()\n",
    "            \n",
    "            if(i_batch % 10 ==0):\n",
    "                print(e, i_batch,loss.item(),(\"badyo\" if last_loss < loss.item() else \"ghatyo\"))\n",
    "                last_loss = loss.item()\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = dict(x = [2,3,4], y= [2,3,4], z= [6,7,9])\n",
    "c['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_net = StockNN([2,2,3,3,4,4], 0, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 810170.875 badyo\n",
      "0 10 763015.875 ghatyo\n",
      "0 20 774417.5 badyo\n",
      "0 30 741498.1875 ghatyo\n",
      "0 40 640337.5625 ghatyo\n",
      "0 50 606032.6875 ghatyo\n",
      "0 60 529407.75 ghatyo\n",
      "0 70 572362.625 badyo\n",
      "0 80 586112.3125 badyo\n",
      "0 90 584407.25 ghatyo\n",
      "0 100 624990.0625 badyo\n",
      "0 110 600077.1875 ghatyo\n",
      "0 120 642758.75 badyo\n",
      "0 130 1003568.75 badyo\n",
      "0 140 1897890.0 badyo\n",
      "0 150 1543297.625 ghatyo\n",
      "0 160 1301709.375 ghatyo\n",
      "0 170 1253706.125 ghatyo\n",
      "0 180 1426825.625 badyo\n",
      "0 190 1924588.875 badyo\n",
      "0 200 1855140.75 ghatyo\n",
      "0 210 1848948.0 ghatyo\n",
      "0 220 1780896.5 ghatyo\n",
      "0 230 1804341.5 badyo\n",
      "0 240 1115264.625 ghatyo\n",
      "0 250 1982470.25 badyo\n",
      "0 260 1860152.375 ghatyo\n",
      "0 270 2101644.0 badyo\n",
      "0 280 2453882.0 badyo\n",
      "0 290 2250665.75 ghatyo\n",
      "0 300 2270982.5 badyo\n",
      "0 310 3058015.25 badyo\n",
      "0 320 3255786.0 badyo\n",
      "0 330 2856163.25 ghatyo\n",
      "0 340 2936747.5 badyo\n",
      "0 350 2548530.5 ghatyo\n",
      "0 360 2693502.0 badyo\n",
      "0 370 2669903.0 ghatyo\n",
      "0 380 2591428.0 ghatyo\n",
      "0 390 2652392.75 badyo\n",
      "0 400 3067545.25 badyo\n",
      "0 410 3222845.0 badyo\n",
      "0 420 2989430.5 ghatyo\n",
      "0 430 2899489.25 ghatyo\n",
      "0 440 3465486.75 badyo\n",
      "0 450 3446012.5 ghatyo\n",
      "0 460 4076724.75 badyo\n",
      "0 470 4321329.5 badyo\n",
      "0 480 6009479.0 badyo\n",
      "0 490 4494489.0 ghatyo\n",
      "0 500 4197007.5 ghatyo\n",
      "0 510 3811695.75 ghatyo\n",
      "0 520 3885279.75 badyo\n",
      "0 530 3999593.75 badyo\n",
      "0 540 3153127.75 ghatyo\n",
      "0 550 3106701.5 ghatyo\n",
      "0 560 3446557.0 badyo\n",
      "0 570 3241428.75 ghatyo\n",
      "0 580 3201596.5 ghatyo\n",
      "0 590 3733443.0 badyo\n",
      "0 600 4692060.5 badyo\n",
      "0 610 5828038.5 badyo\n",
      "0 620 6044659.0 badyo\n",
      "0 630 5323054.5 ghatyo\n",
      "0 640 5142917.0 ghatyo\n",
      "0 650 4641786.0 ghatyo\n",
      "0 660 5054496.5 badyo\n",
      "0 670 4848680.5 ghatyo\n",
      "0 680 4275545.5 ghatyo\n",
      "0 690 2533193.25 ghatyo\n",
      "0 700 2444924.25 ghatyo\n",
      "0 710 2960740.25 badyo\n",
      "0 720 3016198.0 badyo\n",
      "0 730 3451205.5 badyo\n",
      "0 740 3421478.5 ghatyo\n",
      "0 750 3128297.75 ghatyo\n",
      "0 760 3040455.5 ghatyo\n",
      "0 770 2947053.25 ghatyo\n",
      "0 780 3206684.25 badyo\n",
      "0 790 2442195.25 ghatyo\n",
      "0 800 3111026.75 badyo\n",
      "0 810 3054956.5 ghatyo\n",
      "0 820 4566202.5 badyo\n",
      "0 830 5409334.5 badyo\n",
      "0 840 5825437.0 badyo\n",
      "0 850 5495805.5 ghatyo\n",
      "0 860 5396444.5 ghatyo\n",
      "0 870 4865310.5 ghatyo\n",
      "0 880 4450117.0 ghatyo\n",
      "0 890 4154948.75 ghatyo\n",
      "0 900 2966183.0 ghatyo\n",
      "0 910 2644682.0 ghatyo\n",
      "0 920 2641644.75 ghatyo\n",
      "0 930 3042970.75 badyo\n",
      "0 940 2970443.75 ghatyo\n",
      "0 950 2991427.0 badyo\n",
      "0 960 2995131.25 badyo\n",
      "0 970 3650833.0 badyo\n",
      "0 980 3758725.0 badyo\n",
      "0 990 4497412.0 badyo\n",
      "0 1000 4180501.25 ghatyo\n",
      "0 1010 4233421.0 badyo\n",
      "0 1020 4517466.0 badyo\n",
      "0 1030 4947639.0 badyo\n",
      "0 1040 4766335.5 ghatyo\n",
      "0 1050 4639888.5 ghatyo\n",
      "1 0 641304.25 ghatyo\n",
      "1 10 563795.5625 ghatyo\n",
      "1 20 574298.6875 badyo\n",
      "1 30 546665.8125 ghatyo\n",
      "1 40 460981.8125 ghatyo\n",
      "1 50 433714.21875 ghatyo\n",
      "1 60 369909.78125 ghatyo\n",
      "1 70 406850.5625 badyo\n",
      "1 80 419235.375 badyo\n",
      "1 90 418688.78125 ghatyo\n",
      "1 100 453795.21875 badyo\n",
      "1 110 433245.90625 ghatyo\n",
      "1 120 470298.9375 badyo\n",
      "1 130 785608.9375 badyo\n",
      "1 140 1596220.0 badyo\n",
      "1 150 1274052.875 ghatyo\n",
      "1 160 1056866.875 ghatyo\n",
      "1 170 1014818.625 ghatyo\n",
      "1 180 1172315.625 badyo\n",
      "1 190 1628342.375 badyo\n",
      "1 200 1565845.25 ghatyo\n",
      "1 210 1561444.0 ghatyo\n",
      "1 220 1500158.5 ghatyo\n",
      "1 230 1522837.375 badyo\n",
      "1 240 897329.0625 ghatyo\n",
      "1 250 1688977.5 badyo\n",
      "1 260 1577233.625 ghatyo\n",
      "1 270 1801261.125 badyo\n",
      "1 280 2129533.5 badyo\n",
      "1 290 1941621.125 ghatyo\n",
      "1 300 1961540.5 badyo\n",
      "1 310 2698304.75 badyo\n",
      "1 320 2885482.0 badyo\n",
      "1 330 2511115.25 ghatyo\n",
      "1 340 2587723.5 badyo\n",
      "1 350 2225019.0 ghatyo\n",
      "1 360 2361438.75 badyo\n",
      "1 370 2340130.5 ghatyo\n",
      "1 380 2267434.5 ghatyo\n",
      "1 390 2325193.5 badyo\n",
      "1 400 2715595.5 badyo\n",
      "1 410 2862565.0 badyo\n",
      "1 420 2643515.25 ghatyo\n",
      "1 430 2559608.25 ghatyo\n",
      "1 440 3093581.5 badyo\n",
      "1 450 3075813.75 ghatyo\n",
      "1 460 3673801.5 badyo\n",
      "1 470 3906823.5 badyo\n",
      "1 480 5519501.0 badyo\n",
      "1 490 4072706.75 ghatyo\n",
      "1 500 3790240.5 ghatyo\n",
      "1 510 3424937.25 ghatyo\n",
      "1 520 3495072.25 badyo\n",
      "1 530 3603878.5 badyo\n",
      "1 540 2803206.25 ghatyo\n",
      "1 550 2759700.0 ghatyo\n",
      "1 560 3080780.5 badyo\n",
      "1 570 2887252.75 ghatyo\n",
      "1 580 2849891.0 ghatyo\n",
      "1 590 3353061.75 badyo\n",
      "1 600 4290469.0 badyo\n",
      "1 610 5354177.0 badyo\n",
      "1 620 5563166.0 badyo\n",
      "1 630 4872182.0 ghatyo\n",
      "1 640 4700206.0 ghatyo\n",
      "1 650 4221936.5 ghatyo\n",
      "1 660 4616168.5 badyo\n",
      "1 670 4419766.0 ghatyo\n",
      "1 680 3873538.0 ghatyo\n",
      "1 690 2226152.25 ghatyo\n",
      "1 700 2143571.25 ghatyo\n",
      "1 710 2628252.0 badyo\n",
      "1 720 2680644.25 badyo\n",
      "1 730 3091710.0 badyo\n",
      "1 740 3063698.0 ghatyo\n",
      "1 750 2786731.5 ghatyo\n",
      "1 760 2703963.5 ghatyo\n",
      "1 770 2616024.25 ghatyo\n",
      "1 780 2861061.5 badyo\n",
      "1 790 2141915.25 ghatyo\n",
      "1 800 2770950.0 badyo\n",
      "1 810 2718144.0 ghatyo\n",
      "1 820 4152351.0 badyo\n",
      "1 830 4958127.5 badyo\n",
      "1 840 5356898.0 badyo\n",
      "1 850 5041033.5 ghatyo\n",
      "1 860 4945905.5 ghatyo\n",
      "1 870 4438013.0 ghatyo\n",
      "1 880 4041886.5 ghatyo\n",
      "1 890 3760823.5 ghatyo\n",
      "1 900 2634706.75 ghatyo\n",
      "1 910 2332250.25 ghatyo\n",
      "1 920 2329428.75 ghatyo\n",
      "1 930 2707195.5 badyo\n",
      "1 940 2638847.5 ghatyo\n",
      "1 950 2658660.75 badyo\n",
      "1 960 2662185.0 badyo\n",
      "1 970 3282259.25 badyo\n",
      "1 980 3384628.0 badyo\n",
      "1 990 4087295.0 badyo\n",
      "1 1000 3785447.5 ghatyo\n",
      "1 1010 3835801.5 badyo\n",
      "1 1020 4106386.0 badyo\n",
      "1 1030 4516954.5 badyo\n",
      "1 1040 4343762.0 ghatyo\n",
      "1 1050 4223043.0 ghatyo\n",
      "2 0 520240.21875 ghatyo\n",
      "2 10 424883.0 ghatyo\n",
      "2 20 434683.0 badyo\n",
      "2 30 410728.75 ghatyo\n",
      "2 40 336986.34375 ghatyo\n",
      "2 50 313775.84375 ghatyo\n",
      "2 60 259925.9375 ghatyo\n",
      "2 70 291078.75 badyo\n",
      "2 80 301614.5625 badyo\n",
      "2 90 301261.15625 ghatyo\n",
      "2 100 331257.4375 badyo\n",
      "2 110 313843.46875 ghatyo\n",
      "2 120 345601.25 badyo\n",
      "2 130 621777.1875 badyo\n",
      "2 140 1359713.75 badyo\n",
      "2 150 1063944.625 ghatyo\n",
      "2 160 866498.25 ghatyo\n",
      "2 170 828605.8125 ghatyo\n",
      "2 180 971616.0625 badyo\n",
      "2 190 1390299.5 badyo\n",
      "2 200 1332764.875 ghatyo\n",
      "2 210 1328869.125 ghatyo\n",
      "2 220 1272537.125 ghatyo\n",
      "2 230 1293587.5 badyo\n",
      "2 240 723637.625 ghatyo\n",
      "2 250 1447371.125 badyo\n",
      "2 260 1344223.375 ghatyo\n",
      "2 270 1551776.25 badyo\n",
      "2 280 1857631.875 badyo\n",
      "2 290 1682578.5 ghatyo\n",
      "2 300 1701289.75 badyo\n",
      "2 310 2391658.5 badyo\n",
      "2 320 2568257.0 badyo\n",
      "2 330 2215978.5 ghatyo\n",
      "2 340 2288152.5 badyo\n",
      "2 350 1948062.125 ghatyo\n",
      "2 360 2075999.375 badyo\n",
      "2 370 2056180.25 ghatyo\n",
      "2 380 1988225.25 ghatyo\n",
      "2 390 2042485.875 badyo\n",
      "2 400 2409497.5 badyo\n",
      "2 410 2548210.75 badyo\n",
      "2 420 2341936.0 ghatyo\n",
      "2 430 2263146.0 ghatyo\n",
      "2 440 2766911.5 badyo\n",
      "2 450 2750261.5 ghatyo\n",
      "2 460 3317323.25 badyo\n",
      "2 470 3539086.0 badyo\n",
      "2 480 5080868.0 badyo\n",
      "2 490 3697339.25 ghatyo\n",
      "2 500 3428570.75 ghatyo\n",
      "2 510 3081704.0 ghatyo\n",
      "2 520 3148368.5 badyo\n",
      "2 530 3251798.5 badyo\n",
      "2 540 2493860.5 ghatyo\n",
      "2 550 2452938.25 ghatyo\n",
      "2 560 2756263.5 badyo\n",
      "2 570 2573486.0 ghatyo\n",
      "2 580 2538320.25 ghatyo\n",
      "2 590 3014448.0 badyo\n",
      "2 600 3937768.25 badyo\n",
      "2 610 4924151.5 badyo\n",
      "2 620 5124746.5 badyo\n",
      "2 630 4462540.5 ghatyo\n",
      "2 640 4298087.0 ghatyo\n",
      "2 650 3841358.75 ghatyo\n",
      "2 660 4217879.0 badyo\n",
      "2 670 4030299.25 ghatyo\n",
      "2 680 3509563.25 ghatyo\n",
      "2 690 1952447.125 ghatyo\n",
      "2 700 1875224.0 ghatyo\n",
      "2 710 2330225.25 badyo\n",
      "2 720 2379647.0 badyo\n",
      "2 730 2767872.0 badyo\n",
      "2 740 2741441.25 ghatyo\n",
      "2 750 2479866.0 ghatyo\n",
      "2 760 2401888.5 ghatyo\n",
      "2 770 2319113.25 ghatyo\n",
      "2 780 2550216.5 badyo\n",
      "2 790 1874222.875 ghatyo\n",
      "2 800 2465321.0 badyo\n",
      "2 810 2415593.75 ghatyo\n",
      "2 820 3776381.0 badyo\n",
      "2 830 4546539.0 badyo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-2a1e63ba3096>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnepse_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-cabcce0d9f51>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(NN, data, val_frac, max_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train(stock_net, nepse_data, max_epochs= 10, batch_size=1, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2037]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1899]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2095]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2060]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2068]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2340]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2159]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2126]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1671]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1680]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1881]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1633]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1311]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1288]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1336]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1466]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1478]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1485]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1319]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1216]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1197]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1284]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1464]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1466]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1464]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1480]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1293]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1497]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1467]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1518]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1489]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1492]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1515]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1337]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1261]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1258]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1198]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1462]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1493]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1225]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1257]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1279]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1484]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1506]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1499]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1473]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1264]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1278]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1490]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1483]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1368]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1188]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1220]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1299]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1286]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1449]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1445]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1445]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1509]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1477]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1376]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1278]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1497]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1509]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1424]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1489]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1214]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1228]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1424]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1405]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1404]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1020]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1208]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1218]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1059]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0953]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1081]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0999]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0977]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1132]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1205]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0917]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1203]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1263]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1986]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1248]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1275]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0798]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0943]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0871]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1064]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1436]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1642]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1162]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1201]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1077]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0965]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1072]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0890]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1055]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1301]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1282]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1235]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1285]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1288]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1303]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1306]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1284]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1265]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1262]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1268]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0995]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1026]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0975]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1248]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1267]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1000]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0914]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0947]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0982]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1203]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1183]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1103]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0880]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0916]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0882]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0877]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0881]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0877]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1075]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0938]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0763]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1134]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1240]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1161]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1147]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1061]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0866]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1066]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1171]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1168]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1191]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1176]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1111]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1173]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1135]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1145]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1156]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1223]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1218]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1210]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1189]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1194]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1213]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1223]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1206]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1231]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0942]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0976]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0989]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0953]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1139]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1150]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1163]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1202]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1230]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1235]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1231]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1236]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1229]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1231]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1259]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1392]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1939]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2007]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1842]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1811]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1802]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2057]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2094]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2123]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2077]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1741]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1451]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1513]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1124]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1028]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1196]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1239]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1741]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1649]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1598]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1230]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1260]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1635]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1628]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1603]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1300]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1304]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1217]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1184]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1193]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1189]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1452]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1371]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1332]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1416]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1443]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1475]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1449]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1432]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1666]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1674]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1676]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1669]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1437]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1569]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1568]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1585]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1574]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1579]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1621]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1302]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1258]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1300]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1294]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1480]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1506]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1452]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1299]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1077]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1079]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1159]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1075]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1359]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1413]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1083]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1333]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1194]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1153]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1616]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1614]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1606]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1651]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1641]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1620]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1643]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1644]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1656]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1648]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1583]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1579]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1593]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1644]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1610]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1582]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1659]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1662]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1649]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1630]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1581]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1672]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1665]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1663]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1670]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1392]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1646]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1451]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1575]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1591]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1572]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1237]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1578]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1595]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1576]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1575]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1570]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1582]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1583]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1594]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1593]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1321]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1611]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1609]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1568]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1567]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1568]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1520]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1283]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1335]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1411]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1199]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1239]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1291]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1233]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1339]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1491]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1490]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1417]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1331]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1444]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1520]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1571]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1593]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1591]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1607]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1627]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1597]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1580]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1585]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1581]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1410]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1292]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1337]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1302]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1295]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1125]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1456]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1517]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1469]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1478]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1478]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1479]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1501]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1224]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1251]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1265]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1312]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1297]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1335]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1293]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1086]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1106]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1089]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1324]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1352]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1459]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1420]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1420]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1403]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1174]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1465]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1570]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1715]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1091]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1153]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1374]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1638]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1800]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1129]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1346]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1656]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1118]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1259]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1151]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1388]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1673]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1608]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1578]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1621]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1637]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1700]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1670]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1324]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1249]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1638]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1502]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1595]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1574]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1628]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1365]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1520]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1491]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1596]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1553]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1603]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1604]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1633]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1606]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1632]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1682]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1304]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1682]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1526]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1596]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1309]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1562]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1356]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1465]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1426]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1529]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1542]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1596]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1461]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1225]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1229]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1299]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1252]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1474]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1574]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1623]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1414]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1251]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1222]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1208]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1417]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1364]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1069]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1083]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1180]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0716]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0764]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0800]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0521]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0354]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0689]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0767]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0679]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0672]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0662]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0669]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0677]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0723]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0755]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0795]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0757]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0830]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0665]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1113]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0672]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0697]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0858]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0953]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0674]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1040]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1129]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1310]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1254]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1089]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1281]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1321]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1310]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1274]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1371]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1365]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1368]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1374]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1360]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1399]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1360]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1326]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1314]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1443]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1365]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1383]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1151]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1405]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1432]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1304]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1469]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1581]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1363]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1570]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1431]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1494]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1457]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1334]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1387]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1369]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1267]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1092]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1159]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1372]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1379]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1287]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1390]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1467]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1451]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1400]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1402]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1407]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1402]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1386]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1288]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1290]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1355]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1444]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1440]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1307]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1560]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2111]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1784]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2379]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2267]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1876]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1884]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1887]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1906]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1932]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1909]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1911]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2111]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1971]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1806]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1731]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1615]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1521]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1443]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1508]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1395]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1392]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1492]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1591]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1479]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1722]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1592]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1691]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1553]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1295]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1376]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1407]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1312]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1521]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1441]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1177]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1176]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1287]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1205]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1448]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1485]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1522]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1528]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1515]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1497]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1537]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1562]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1571]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1587]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1600]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1585]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1572]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1540]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1513]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1578]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1588]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1515]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1564]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1563]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1566]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1589]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1577]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1576]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1316]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1579]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1382]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1566]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1602]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1428]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1290]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1505]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1689]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1789]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1290]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1243]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1284]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1204]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1176]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1211]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1291]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1511]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1540]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1526]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1518]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1541]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1283]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1437]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1116]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1248]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1487]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1053]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1034]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1029]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1387]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1057]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1498]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1421]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1054]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1014]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1041]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1642]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1830]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1947]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1962]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1813]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1401]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1351]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1716]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1582]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1631]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1419]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1655]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1210]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1325]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1342]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1371]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1721]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1718]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1630]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1594]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1367]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1613]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1500]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1480]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1696]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1575]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1656]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1755]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1404]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1655]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1493]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1492]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1676]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1460]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1728]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1761]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1614]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1531]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1353]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1601]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1637]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1689]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1698]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1590]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1401]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1421]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1442]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1446]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1632]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1532]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1412]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1424]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1224]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1208]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0741]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0599]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1514]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1661]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1881]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1909]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1912]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1907]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1928]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1999]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1923]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1925]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1913]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1796]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1639]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1671]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1696]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1438]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1327]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1321]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1436]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1583]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1620]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1642]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1586]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1341]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1382]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1375]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1532]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1553]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1503]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1562]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1282]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1305]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1626]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1577]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1540]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1535]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1558]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1554]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1335]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1519]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1565]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1516]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1430]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1354]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1272]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1226]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1334]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1337]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1359]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1291]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1320]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1386]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1325]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1156]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1046]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1385]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1382]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1059]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1108]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1358]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1532]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1450]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1450]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1493]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1531]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1537]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1491]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1482]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1465]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1509]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1439]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1402]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1505]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1542]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1538]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1620]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1654]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1577]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1415]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1381]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1317]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1406]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1378]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1534]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1510]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1192]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1317]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1466]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1527]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1548]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1523]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1512]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1571]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1559]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1549]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1293]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1435]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1408]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1426]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1453]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1486]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1507]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1506]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1453]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1708]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1749]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1694]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1464]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1545]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1547]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1655]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1595]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1594]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1617]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1640]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1346]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1485]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1556]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1209]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1266]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1259]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1495]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1539]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1551]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1561]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1541]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1541]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1848]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1650]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1533]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2084]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.2034]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1853]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1870]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1934]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1924]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1936]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1917]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1876]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1868]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1889]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1878]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1843]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1849]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1860]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1848]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1895]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1584]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1458]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1567]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1716]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1750]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1536]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1529]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1473]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1401]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1496]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1513]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1552]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1761]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1827]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1944]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1795]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1468]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1429]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1627]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1504]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1380]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1394]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1399]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1407]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1387]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1376]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1372]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1440]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1528]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1529]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1436]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1408]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1400]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1405]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1612]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1686]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1444]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1550]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1543]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1463]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1437]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1544]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1605]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1370]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1389]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1632]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1525]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1430]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1423]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1434]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1555]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1546]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1530]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1453]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1415]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1425]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1472]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1697]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1488]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1386]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1722]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1454]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1395]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1398]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1432]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1679]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1648]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1475]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1318]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1325]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1422]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1327]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1314]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1524]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1414]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1393]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1449]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1557]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1384]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1360]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0.1471]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "stock_net.eval()\n",
    "hc = stock_net.init_hidden(1)\n",
    "train_data, validate_data = train_validate_set(nepse_data,0.1)\n",
    "dataloader = DataLoader(train_data, batch_size=1)\n",
    "milyo = 0\n",
    "for train in dataloader:\n",
    "    out, hc= stock_net(train,hc)\n",
    "    print(out)\n",
    "    if (train[\"label\"].data.cpu().numpy() ==np.argmax(out.data.cpu().numpy())):\n",
    "        milyo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n"
     ]
    }
   ],
   "source": [
    "print(milyo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
